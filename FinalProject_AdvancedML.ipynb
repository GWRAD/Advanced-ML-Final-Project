{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:49:52.758323Z",
          "iopub.status.busy": "2024-10-29T20:49:52.757033Z",
          "iopub.status.idle": "2024-10-29T20:49:56.237061Z",
          "shell.execute_reply": "2024-10-29T20:49:56.235845Z",
          "shell.execute_reply.started": "2024-10-29T20:49:52.758202Z"
        },
        "id": "5WqdYDI7bTN3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2dINr7lnU65",
        "outputId": "06ffec3c-4473-48b9-f734-cfd412292605"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total counts of fraud and non-fraud transactions:\n",
            "Is Fraud?\n",
            "No     24357143\n",
            "Yes       29757\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Total Fraud records: 29757\n",
            "Total Non-Fraud records: 24357143\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the CSV file\n",
        "file_path = r\"C:\\Users\\radhi\\Downloads\\archive (1)\\credit_card_transactions-ibm_v2.csv\"\n",
        "\n",
        "# Read the entire CSV (if it's not too large for memory)\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Check total counts of fraud and non-fraud\n",
        "print(\"Total counts of fraud and non-fraud transactions:\")\n",
        "print(df['Is Fraud?'].value_counts())\n",
        "\n",
        "# Separate Fraudulent and Non-Fraudulent records\n",
        "fraud = df[df['Is Fraud?'] == 'Yes']\n",
        "non_fraud = df[df['Is Fraud?'] == 'No']\n",
        "\n",
        "print(f\"\\nTotal Fraud records: {len(fraud)}\")\n",
        "print(f\"Total Non-Fraud records: {len(non_fraud)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnrcwc05vI0Q"
      },
      "source": [
        "--------Data Pre Processing-------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuSXQ7BMnU65",
        "outputId": "e11b8513-c42b-432e-a19b-45cb142db1e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled Data Distribution:\n",
            "Is Fraud?\n",
            "No     90000\n",
            "Yes    10000\n",
            "Name: count, dtype: int64\n",
            "Sampled Data Shape: (100000, 15)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the CSV file\n",
        "file_path = r\"C:\\Users\\radhi\\Downloads\\archive (1)\\credit_card_transactions-ibm_v2.csv\"\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Filter Fraudulent and Non-Fraudulent records\n",
        "fraud = df[df['Is Fraud?'] == 'Yes']\n",
        "non_fraud = df[df['Is Fraud?'] == 'No']\n",
        "\n",
        "# Selecting 100000 records from the dataset\n",
        "# Determine the required number of records\n",
        "fraud_count = 10000\n",
        "non_fraud_count = 100000 - fraud_count  # Remaining\n",
        "\n",
        "# Sample the required number of records\n",
        "fraud_sample = fraud.sample(n=fraud_count, random_state=42)\n",
        "non_fraud_sample = non_fraud.sample(n=non_fraud_count, random_state=42)\n",
        "\n",
        "# Combine and shuffle the samples\n",
        "sampled_df = pd.concat([fraud_sample, non_fraud_sample]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Verify the counts\n",
        "print(\"Sampled Data Distribution:\")\n",
        "print(sampled_df['Is Fraud?'].value_counts())\n",
        "print(f\"Sampled Data Shape: {sampled_df.shape}\")\n",
        "\n",
        "# Save the sampled data to a new CSV if needed\n",
        "output_path = r\"C:\\Users\\radhi\\Downloads\\sampled_credit_card_transactions.csv\"\n",
        "sampled_df.to_csv(output_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:53:22.630140Z",
          "iopub.status.busy": "2024-10-29T20:53:22.629060Z",
          "iopub.status.idle": "2024-10-29T20:53:22.723946Z",
          "shell.execute_reply": "2024-10-29T20:53:22.722700Z",
          "shell.execute_reply.started": "2024-10-29T20:53:22.630076Z"
        },
        "id": "pfkHcc1DbTN5",
        "outputId": "522f52b9-204e-4524-c86c-32ae04741d2f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   User            100000 non-null  int64  \n",
            " 1   Card            100000 non-null  int64  \n",
            " 2   Year            100000 non-null  int64  \n",
            " 3   Month           100000 non-null  int64  \n",
            " 4   Day             100000 non-null  int64  \n",
            " 5   Time            100000 non-null  object \n",
            " 6   Amount          100000 non-null  object \n",
            " 7   Use Chip        100000 non-null  object \n",
            " 8   Merchant Name   100000 non-null  int64  \n",
            " 9   Merchant City   100000 non-null  object \n",
            " 10  Merchant State  83768 non-null   object \n",
            " 11  Zip             81099 non-null   float64\n",
            " 12  MCC             100000 non-null  int64  \n",
            " 13  Errors?         1847 non-null    object \n",
            " 14  Is Fraud?       100000 non-null  object \n",
            "dtypes: float64(1), int64(7), object(7)\n",
            "memory usage: 11.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df = sampled_df\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:53:31.547264Z",
          "iopub.status.busy": "2024-10-29T20:53:31.546845Z",
          "iopub.status.idle": "2024-10-29T20:53:31.566399Z",
          "shell.execute_reply": "2024-10-29T20:53:31.565064Z",
          "shell.execute_reply.started": "2024-10-29T20:53:31.547230Z"
        },
        "id": "4lJtb_62bTN5",
        "outputId": "619ebdc2-fdf5-411a-b1fe-795ae6924eae",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 15)"
            ]
          },
          "execution_count": 447,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df [df['Is Fraud?'] == 'Yes'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:53:36.124544Z",
          "iopub.status.busy": "2024-10-29T20:53:36.123398Z",
          "iopub.status.idle": "2024-10-29T20:53:36.502656Z",
          "shell.execute_reply": "2024-10-29T20:53:36.501173Z",
          "shell.execute_reply.started": "2024-10-29T20:53:36.124492Z"
        },
        "id": "Q7LVIwmMbTN5",
        "outputId": "c236260f-6128-4ecb-aba7-0e5fb4d39f74",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
              " [Text(0, 0, 'Errors?'),\n",
              "  Text(1, 0, 'Zip'),\n",
              "  Text(2, 0, 'Merchant State'),\n",
              "  Text(3, 0, 'User'),\n",
              "  Text(4, 0, 'Card'),\n",
              "  Text(5, 0, 'Year'),\n",
              "  Text(6, 0, 'Month'),\n",
              "  Text(7, 0, 'Day'),\n",
              "  Text(8, 0, 'Time'),\n",
              "  Text(9, 0, 'Amount'),\n",
              "  Text(10, 0, 'Use Chip'),\n",
              "  Text(11, 0, 'Merchant Name'),\n",
              "  Text(12, 0, 'Merchant City'),\n",
              "  Text(13, 0, 'MCC'),\n",
              "  Text(14, 0, 'Is Fraud?')])"
            ]
          },
          "execution_count": 448,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAInCAYAAAB+wpi7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABsU0lEQVR4nO3dd1gU1/s28HsXkV4sCBKpigUE7L037F1jizX23kuU2DUmli+xYCcasaOJUbH33nsHlahgLICAIMJ5//DHvq6Agszswnh/rmuvwMwyzwNZ4d4zZ86ohBACRERERAql1ncDRERERHJi2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYIcpBVCoVJk+eLPlxnZ2d0b17d8mPqw+1atVCrVq19N2Gzj18+BAqlQoBAQGyHF9JrxH69jDsEOlYQEAAVCoVVCoVjh8/nmq/EAIODg5QqVRo2rSpHjrUjaCgIKhUKqxYsSLd5+zbtw8qlQp+fn467Czrbt26BZVKBWNjY0RGRuq7HaJvXi59N0D0rTI2NkZgYCCqVaumtf3IkSP4999/YWRklOpr3r59i1y5pP9ne+fOHajVun3v06RJE1hZWSEwMBA//vhjms8JDAyEgYEBOnTooNPesurPP/+EnZ0dXr9+jS1btqT7/eUk+niNEEmFr1wiPWncuDE2b96M9+/fa20PDAxE2bJlYWdnl+prjI2NZQk7RkZGMDQ0lPy4X6rZtm1bHDlyBE+fPk21Pz4+Htu2bUP9+vVRoEABnfaWFUIIBAYGolOnTmjcuDHWrVun75YkoY/XCJFUGHaI9KRjx454+fIl9u3bp9n27t07bNmyBZ06dUrzaz6ds/PmzRsMGzYMzs7OMDIyQoECBVC/fn1cvHhR85x79+6hTZs2sLOzg7GxMQoVKoQOHTogKipK85xP52OknGo7ceIERowYARsbG5iZmaFVq1b477//tHpKTk7G5MmTYW9vD1NTU9SuXRs3b97M0ByPLl26IDk5GRs2bEi1b+fOnYiKikLnzp0BAKtXr0adOnVQoEABGBkZwd3dHUuWLPns8T/+Xh4+fKi1/fDhw1CpVDh8+LDW9jNnzqBhw4awsrKCqakpatasiRMnTnyxTooTJ07g4cOH6NChAzp06ICjR4/i33//TfU8Z2dnNG3aFMePH0eFChVgbGwMV1dXrFmzRut5r169wqhRo+Dp6Qlzc3NYWlqiUaNGuHLlymf7WL16NVQqFS5dupRq38yZM2FgYIAnT54A+LrXSGJiIqZMmQI3NzcYGxsjX758qFatmtbrmSi7YNgh0hNnZ2dUrlwZ69ev12zbvXs3oqKiMnzapl+/fliyZAnatGmDxYsXY9SoUTAxMcGtW7cAfAhPPj4+OH36NAYPHoxFixahT58+CAkJydBcksGDB+PKlSv4+eef0b9/f+zYsQODBg3Ses748eMxZcoUlCtXDr/++ivc3Nzg4+OD2NjYLx6/Ro0aKFSoEAIDA1PtCwwMhKmpKVq2bAkAWLJkCZycnDBhwgTMnTsXDg4OGDBgABYtWvTlH1QGHTx4EDVq1EB0dDR+/vlnzJw5E5GRkahTpw7Onj2boWOsW7cOhQsXRvny5dGsWTOYmppq/T/+2P3799G2bVvUr18fc+fORZ48edC9e3fcuHFD85yQkBBs374dTZs2xbx58zB69Ghcu3YNNWvWTHNELEXbtm1hYmKS5sjSunXrUKtWLXz33Xdf/RqZPHkypkyZgtq1a2PhwoX46aef4OjoqBW0ibINQUQ6tXr1agFAnDt3TixcuFBYWFiIuLg4IYQQ7dq1E7Vr1xZCCOHk5CSaNGmi9bUAxM8//6z53MrKSgwcODDdWpcuXRIAxObNmz/bk5OTk+jWrVuqHuvVqyeSk5M124cPHy4MDAxEZGSkEEKI8PBwkStXLtGyZUut402ePFkA0DpmekaPHi0AiDt37mi2RUVFCWNjY9GxY0fNtpSf0cd8fHyEq6ur1raaNWuKmjVrpvpeQkNDtZ536NAhAUAcOnRICCFEcnKycHNzEz4+Plrfc1xcnHBxcRH169f/4vfy7t07kS9fPvHTTz9ptnXq1El4e3uneq6Tk5MAII4eParZ9vz5c2FkZCRGjhyp2RYfHy+SkpK0vjY0NFQYGRmJqVOnam0DIFavXq3Z1rFjR2Fvb6/19RcvXtR63te+Rry9vVO9PomyK47sEOlR+/bt8fbtW/zzzz948+YN/vnnn3RPYaXF2toaZ86cSfcdvpWVFQBgz549iIuLy3R/ffr0gUql0nxevXp1JCUl4dGjRwCAAwcO4P379xgwYIDW1w0ePDjDNbp06QIAWqM7W7duRXx8vOYUFgCYmJhoPo6KisKLFy9Qs2ZNhISEaJ1u+VqXL1/GvXv30KlTJ7x8+RIvXrzAixcvEBsbi7p16+Lo0aNITk7+7DF2796Nly9fomPHjpptHTt2xJUrV7RGa1K4u7ujevXqms9tbGxQrFgxhISEaLYZGRlpJgYnJSXh5cuXMDc3R7Fixb44itK1a1c8ffoUhw4d0mxbt24dTExM0KZNGwBf/xqxtrbGjRs3cO/evQx/DZG+MOwQ6ZGNjQ3q1auHwMBABAUFISkpCW3bts3w18+ZMwfXr1+Hg4MDKlSogMmTJ2v9oXRxccGIESOwYsUK5M+fHz4+Pli0aFGGw4Gjo6PW53ny5AEAvH79GgA0oadIkSJaz8ubN6/muV/i5eWFkiVLap3qCQwM1PSb4sSJE6hXrx7MzMxgbW0NGxsbTJgwAQAkCTspf7S7desGGxsbrceKFSuQkJDwxTp//vknXFxcYGRkhPv37+P+/fsoXLgwTE1N0zyd9OnPF/jwM075+QIf5kTNnz8fbm5uMDIyQv78+WFjY4OrV69+sZ/69eujYMGCmtrJyclYv349WrRoAQsLCwBf/xqZOnUqIiMjUbRoUXh6emL06NG4evXqZ7+GSF8Ydoj0rFOnTti9ezf8/f3RqFEjWFtbZ/hr27dvj5CQEPz++++wt7fHr7/+Cg8PD+zevVvznLlz5+Lq1auYMGEC3r59iyFDhsDDwyPNSbOfMjAwSHO7ECLDPWZEly5dcPfuXZw/fx7h4eE4dOgQ2rdvr7ny7MGDB6hbty5evHiBefPmYefOndi3bx+GDx8OAJ8dcfl4ZOpjSUlJWp+nHOPXX3/Fvn370nyYm5unWyc6Oho7duxAaGgo3NzcNA93d3fExcUhMDAw1c8tIz/fmTNnYsSIEahRowb+/PNP7NmzB/v27YOHh8cXR5oMDAzQqVMnzUjZoUOH8PTpU81oWoqveY3UqFEDDx48wKpVq1CyZEmsWLECZcqU+ey6SUT6wnV2iPSsVatW6Nu3L06fPo2NGzdm+usLFiyIAQMGYMCAAXj+/DnKlCmDGTNmoFGjRprneHp6wtPTExMnTsTJkydRtWpV+Pv7Y/r06Vnq3cnJCcCHibYuLi6a7S9fvtQanfiSjh07Yvz48QgMDISTkxOSkpK0TmHt2LEDCQkJ+Pvvv7VGQz4+PZOelBGmTyfbpoxKpShcuDAAwNLSEvXq1ctw7ymCgoIQHx+PJUuWIH/+/Fr77ty5g4kTJ+LEiROp1lX6ki1btqB27dpYuXKl1vbIyMhUddLStWtXzJ07Fzt27MDu3bthY2OjNWKW4mteI3nz5kWPHj3Qo0cPxMTEoEaNGpg8ebIi1hUiZWHYIdIzc3NzLFmyBA8fPkSzZs0y/HVJSUmIiYnRzLkAgAIFCsDe3h4JCQkAPow2mJqaaq3N4+npCbVarXlOVtStWxe5cuXCkiVLUL9+fc32hQsXZuo4jo6OqF69OjZu3Ah7e3u4uLigSpUqmv0pIyAfj3hERUVh9erVXzx2Sog5evQoSpUqBeDDz27ZsmVazytbtiwKFy6M3377DZ06dUo1ivPff//BxsYm3Tp//vknXF1d0a9fv1T7EhISMHv2bKxbty7TYcfAwCDViNDmzZvx5MmTVKcP0+Ll5QUvLy+sWLECp0+fRrdu3bReD1/7Gnn58iXy5cun+dzc3BxFihRBWFhYZr49Ip1g2CHKBrp165bpr3nz5g0KFSqEtm3bwtvbG+bm5ti/fz/OnTuHuXPnAvhwKfWgQYPQrl07FC1aFO/fv8fatWthYGCgmaCaFba2thg6dCjmzp2L5s2bo2HDhrhy5Qp2796N/Pnzp3sKKS1dunRBnz598PTpU/z0009a+xo0aIDcuXOjWbNm6Nu3L2JiYrB8+XIUKFAAz549++xxPTw8UKlSJYwfPx6vXr1C3rx5sWHDhlSLOarVaqxYsQKNGjWCh4cHevToge+++w5PnjzBoUOHYGlpiR07dqRZI2US8JAhQ9Lcb2RkBB8fH2zevBl+fn6ZWpyvadOmmDp1Knr06IEqVarg2rVrWLduHVxdXTN8jK5du2LUqFEAkOoU1te+Rtzd3VGrVi2ULVsWefPmxfnz57Fly5ZUSxMQZQcMO0Q5lKmpKQYMGIC9e/ciKCgIycnJKFKkCBYvXoz+/fsDALy9veHj44MdO3bgyZMnMDU1hbe3N3bv3o1KlSpJ0scvv/wCU1NTLF++HPv370flypWxd+9eVKtWDcbGxhk+Ttu2bTF48GAkJCRoncICgGLFimHLli2YOHEiRo0aBTs7O/Tv3x82Njbo2bPnF4+9bt069O3bF7Nnz4a1tTV69eqF2rVra41GAR9uInrq1ClMmzYNCxcuRExMDOzs7FCxYkX07ds33eNv2LABycnJnx2Za9asGbZu3Yrdu3ejefPmX+w5xYQJExAbG4vAwEBs3LgRZcqUwc6dOzFu3LgMH6Nz584YO3YsChcujAoVKmjt+9rXyJAhQ/D3339j7969SEhIgJOTE6ZPn47Ro0dnuC8iXVEJqWcaEtE3LzIyEnny5MH06dNTjdKQ7r148QIFCxaEr68vJk2apO92iHSOV2MRUZa8ffs21bYFCxYA+DBSQvoXEBCApKQk/PDDD/puhUgveBqLiLJk48aNCAgIQOPGjWFubo7jx49j/fr1aNCgAapWrarv9r5pBw8exM2bNzFjxgy0bNkSzs7O+m6JSC94GouIsuTixYsYM2YMLl++jOjoaNja2qJNmzaYPn36Z9elIfnVqlVLcxn5n3/+ie+++07fLRHpBcMOERERKRrn7BAREZGicc4OPiwT//TpU1hYWGRqXRAiIiLSHyEE3rx5A3t7e80Nc9PCsIMPC4I5ODjouw0iIiL6CmFhYShUqFC6+xl2AM3df8PCwmBpaannboiIiCgjoqOj4eDgoPk7nh6GHfz/uyJbWloy7BAREeUwX5qCwgnKREREpGgMO0RERKRoDDtERESkaAw7REREpGgMO0RERKRoeg07R48eRbNmzWBvbw+VSoXt27dr7RdCwNfXFwULFoSJiQnq1auHe/fuaT3n1atX6Ny5MywtLWFtbY1evXohJiZGh98FERERZWd6DTuxsbHw9vbGokWL0tw/Z84c+Pn5wd/fH2fOnIGZmRl8fHwQHx+veU7nzp1x48YN7Nu3D//88w+OHj2KPn366OpbICIiomwu29wIVKVSYdu2bWjZsiWAD6M69vb2GDlyJEaNGgUAiIqKgq2tLQICAtChQwfcunUL7u7uOHfuHMqVKwcACA4ORuPGjfHvv//C3t4+zVoJCQlISEjQfJ6yKFFUVBTX2SEiIsohoqOjYWVl9cW/39l2zk5oaCjCw8NRr149zTYrKytUrFgRp06dAgCcOnUK1tbWmqADAPXq1YNarcaZM2fSPfasWbNgZWWlefBWEURERMqVbcNOeHg4AMDW1lZru62trWZfeHg4ChQooLU/V65cyJs3r+Y5aRk/fjyioqI0j7CwMIm7JyIiouzim7xdhJGREYyMjPTdBhEREelAth3ZsbOzAwBERERobY+IiNDss7Ozw/Pnz7X2v3//Hq9evdI8h4iIiL5t2TbsuLi4wM7ODgcOHNBsi46OxpkzZ1C5cmUAQOXKlREZGYkLFy5onnPw4EEkJyejYsWKOu+ZiIiIsh+9nsaKiYnB/fv3NZ+Hhobi8uXLyJs3LxwdHTFs2DBMnz4dbm5ucHFxwaRJk2Bvb6+5YqtEiRJo2LAhevfuDX9/fyQmJmLQoEHo0KFDuldiERER0bdFr2Hn/PnzqF27tubzESNGAAC6deuGgIAAjBkzBrGxsejTpw8iIyNRrVo1BAcHw9jYWPM169atw6BBg1C3bl2o1Wq0adMGfn5+Ov9e0vP4MfDihbw18ucHHB3lrUFERJRTZZt1dvQpo9fpZ9bjx0CJEgJxcSrJjpkWU1OBW7dUDDxERPRNyejf72/yaixdefECiItTYeHCSLi5vZelxr17uTBokDVevODoDhERUVoYdnTAze09vLzkCTtERET0edn2aiwiIiIiKTDsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaJl67CTlJSESZMmwcXFBSYmJihcuDCmTZsGIYTmOUII+Pr6omDBgjAxMUG9evVw7949PXZNRERE2Um2Dju//PILlixZgoULF+LWrVv45ZdfMGfOHPz++++a58yZMwd+fn7w9/fHmTNnYGZmBh8fH8THx+uxcyIiIsoucum7gc85efIkWrRogSZNmgAAnJ2dsX79epw9exbAh1GdBQsWYOLEiWjRogUAYM2aNbC1tcX27dvRoUOHNI+bkJCAhIQEzefR0dEyfydERESkL9l6ZKdKlSo4cOAA7t69CwC4cuUKjh8/jkaNGgEAQkNDER4ejnr16mm+xsrKChUrVsSpU6fSPe6sWbNgZWWleTg4OMj7jRAREZHeZOuRnXHjxiE6OhrFixeHgYEBkpKSMGPGDHTu3BkAEB4eDgCwtbXV+jpbW1vNvrSMHz8eI0aM0HweHR3NwENERKRQ2TrsbNq0CevWrUNgYCA8PDxw+fJlDBs2DPb29ujWrdtXH9fIyAhGRkYSdkpERETZVbYOO6NHj8a4ceM0c288PT3x6NEjzJo1C926dYOdnR0AICIiAgULFtR8XUREBEqVKqWPlomIiCibydZzduLi4qBWa7doYGCA5ORkAICLiwvs7Oxw4MABzf7o6GicOXMGlStX1mmvRERElD1l65GdZs2aYcaMGXB0dISHhwcuXbqEefPmoWfPngAAlUqFYcOGYfr06XBzc4OLiwsmTZoEe3t7tGzZUr/NExERUbaQrcPO77//jkmTJmHAgAF4/vw57O3t0bdvX/j6+mqeM2bMGMTGxqJPnz6IjIxEtWrVEBwcDGNjYz12TkRERNmFSny8HPE3Kjo6GlZWVoiKioKlpaVkx714EShbFtiz5wW8vN5LdtyPXb2aCz4++XHhAlCmjCwliIiIsqWM/v3O1nN2iIiIiLKKYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFC3LYSc6Ohrbt2/HrVu3pOiHiIiISFKZDjvt27fHwoULAQBv375FuXLl0L59e3h5eWHr1q2SN0hERESUFZkOO0ePHkX16tUBANu2bYMQApGRkfDz88P06dMlb5CIiIgoKzIddqKiopA3b14AQHBwMNq0aQNTU1M0adIE9+7dk7xBIiIioqzIdNhxcHDAqVOnEBsbi+DgYDRo0AAA8Pr1axgbG0veIBEREVFW5MrsFwwbNgydO3eGubk5HB0dUatWLQAfTm95enpK3R8RERFRlmQ67AwYMAAVKlRAWFgY6tevD7X6w+CQq6sr5+wQERFRtpPpsAMA5cqVg5eXF0JDQ1G4cGHkypULTZo0kbo3IiIioizL9JyduLg49OrVC6ampvDw8MDjx48BAIMHD8bs2bMlb5CIiIgoKzIddsaPH48rV67g8OHDWhOS69Wrh40bN0raHBEREVFWZfo01vbt27Fx40ZUqlQJKpVKs93DwwMPHjyQtDkiIiKirMr0yM5///2HAgUKpNoeGxurFX6IiIiIsoNMh51y5cph586dms9TAs6KFStQuXJl6TojIiIikkCmT2PNnDkTjRo1ws2bN/H+/Xv873//w82bN3Hy5EkcOXJEjh6JiIiIvlqmR3aqVauGy5cv4/379/D09MTevXtRoEABnDp1CmXLlpWjRyIiIqKv9lXr7BQuXBjLly+XuhciIiIiyWU67KSsq5MeR0fHr26GiIiISGqZDjvOzs6fveoqKSkpSw0RERERSSnTYefSpUtanycmJuLSpUuYN28eZsyYIVljRERERFLIdNjx9vZOta1cuXKwt7fHr7/+itatW0vSGBEREZEUMn01VnqKFSuGc+fOSXU4IiIiIklkemQnOjpa63MhBJ49e4bJkyfDzc1NssaIiIiIpJDpsGNtbZ1qgrIQAg4ODtiwYYNkjRERERFJIdNh59ChQ1qfq9Vq2NjYoEiRIsiV66uW7SEiIiKSTabTSc2aNeXog4iIiEgWGQo7f//9d4YP2Lx5869uhoiIiEhqGQo7LVu2zNDBVCoVFxUkIiKibCVDYSc5OVnuPoiIiIhkIdk6O0RERETZ0VddPhUbG4sjR47g8ePHePfunda+IUOGSNIYERERkRS+6t5YjRs3RlxcHGJjY5E3b168ePECpqamKFCgAMMOERERZSuZPo01fPhwNGvWDK9fv4aJiQlOnz6NR48eoWzZsvjtt9/k6JGIiIjoq2U67Fy+fBkjR46EWq2GgYEBEhIS4ODggDlz5mDChAly9EhERET01TIddgwNDaFWf/iyAgUK4PHjxwAAKysrhIWFSdsdgCdPnqBLly7Ily8fTExM4OnpifPnz2v2CyHg6+uLggULwsTEBPXq1cO9e/ck74OIiIhypkyHndKlS2vubl6zZk34+vpi3bp1GDZsGEqWLClpc69fv0bVqlVhaGiI3bt34+bNm5g7dy7y5Mmjec6cOXPg5+cHf39/nDlzBmZmZvDx8UF8fLykvRAREVHOlOkJyjNnzsSbN28AADNmzEDXrl3Rv39/uLm5YdWqVZI298svv8DBwQGrV6/WbHNxcdF8LITAggULMHHiRLRo0QIAsGbNGtja2mL79u3o0KGDpP0QERFRzpPpkZ1y5cqhdu3aAD6cxgoODkZ0dDQuXLgAb29vSZv7+++/Ua5cObRr1w4FChRA6dKlsXz5cs3+0NBQhIeHo169epptVlZWqFixIk6dOpXucRMSEhAdHa31ICIiImXKdNiZPn06QkND5egllZCQECxZsgRubm7Ys2cP+vfvjyFDhuCPP/4AAISHhwMAbG1ttb7O1tZWsy8ts2bNgpWVlebh4OAg3zdBREREepXpsLN582YUKVIEVapUweLFi/HixQs5+gLw4TYVZcqUwcyZM1G6dGn06dMHvXv3hr+/f5aOO378eERFRWkeckysJiIiouwh02HnypUruHr1KmrVqoXffvsN9vb2aNKkCQIDAxEXFydpcwULFoS7u7vWthIlSmiuALOzswMAREREaD0nIiJCsy8tRkZGsLS01HoQERGRMn3VvbE8PDwwc+ZMhISE4NChQ3B2dsawYcM+GzC+RtWqVXHnzh2tbXfv3oWTkxOAD5OV7ezscODAAc3+6OhonDlzBpUrV5a0FyIiIsqZvureWB8zMzODiYkJcufOrblKSyrDhw9HlSpVMHPmTLRv3x5nz57FsmXLsGzZMgCASqXCsGHDMH36dLi5ucHFxQWTJk2Cvb09WrZsKWkvRERElDN91chOaGgoZsyYAQ8PD5QrVw6XLl3ClClTPjsp+GuUL18e27Ztw/r161GyZElMmzYNCxYsQOfOnTXPGTNmDAYPHow+ffqgfPnyiImJQXBwMIyNjSXthYiIiHKmTI/sVKpUCefOnYOXlxd69OiBjh074rvvvpOjNwBA06ZN0bRp03T3q1QqTJ06FVOnTpWtByIiIsq5Mh126tati1WrVqWaOExERESUHWU67MyYMUOOPoiIiIhk8VVzdoiIiIhyCoYdIiIiUjSGHSIiIlI0hh0iIiJStExPUL569Wqa21UqFYyNjeHo6AgjI6MsN0ZEREQkhUyHnVKlSkGlUqW739DQEN9//z2WLl3Khf2IiIhI7zJ9Gmvbtm1wc3PDsmXLcPnyZVy+fBnLli1DsWLFEBgYiJUrV+LgwYOYOHGiHP0SERERZcpXrbPzv//9Dz4+Ppptnp6eKFSoECZNmoSzZ8/CzMwMI0eOxG+//SZps0RERESZlemRnWvXrmnuOv4xJycnXLt2DcCHU13Pnj3LendEREREWZTpsFO8eHHMnj0b796902xLTEzE7NmzUbx4cQDAkydPYGtrK12XRERERF8p06exFi1ahObNm6NQoULw8vIC8GG0JykpCf/88w8AICQkBAMGDJC2UyIiIqKvkOmwU6VKFYSGhmLdunW4e/cuAKBdu3bo1KkTLCwsAAA//PCDtF0SERERfaVMhx0AsLCwQL9+/aTuhYiIiEhyXxV27t27h0OHDuH58+dITk7W2ufr6ytJY0RERERSyHTYWb58Ofr374/8+fPDzs5Oa4FBlUrFsENERETZSqbDzvTp0zFjxgyMHTtWjn6IiIiIJJXpS89fv36Ndu3aydELERERkeQyHXbatWuHvXv3ytELERERkeQyfRqrSJEimDRpEk6fPg1PT08YGhpq7R8yZIhkzRERERFlVabDzrJly2Bubo4jR47gyJEjWvtUKhXDDhEREWUrmQ47oaGhcvRBREREJItMz9khIiIiykkyNLIzYsQITJs2DWZmZhgxYsRnnztv3jxJGiMiIiKSQobCzqVLl5CYmKj5OD0fLzBIRERElB1kKOwcOnQozY+JiIiIsrssz9mJjo7G9u3bcfv2bSn6ISIiIpJUpsNO+/btsXDhQgDA27dvUa5cObRv3x6enp7YunWr5A0SERERZUWmw87Ro0dRvXp1AMC2bdsghEBkZCT8/Pwwffp0yRskIiIiyopMh52oqCjkzZsXABAcHIw2bdrA1NQUTZo0wb179yRvkIiIiCgrMh12HBwccOrUKcTGxiI4OBgNGjQA8OEGocbGxpI3SERERJQVmV5BediwYejcuTPMzc3h5OSEWrVqAfhwesvT01Pq/oiIiIiyJNNhZ8CAAahQoQLCwsJQv359qNUfBodcXV05Z4eIiIiynUyHHQAoV64cypUrBwBISkrCtWvXUKVKFeTJk0fS5oiIiIiyKtNzdoYNG4aVK1cC+BB0atasiTJlysDBwQGHDx+Wuj8iIiKiLMl02NmyZQu8vb0BADt27EBoaChu376N4cOH46effpK8QSIiIqKsyHTYefHiBezs7AAAu3btQrt27VC0aFH07NkT165dk7xBIiIioqzIdNixtbXFzZs3kZSUhODgYNSvXx8AEBcXBwMDA8kbJCIiIsqKTE9Q7tGjB9q3b4+CBQtCpVKhXr16AIAzZ86gePHikjdIRERElBWZDjuTJ09GyZIlERYWhnbt2sHIyAgAYGBggHHjxkneIBEREVFWfNWl523btk21rVu3blluhoiIiEhqGQo7fn5+6NOnD4yNjeHn5/fZ5w4ZMkSSxoiIiIikkKGwM3/+fHTu3BnGxsaYP39+us9TqVQMO0RERJStZCjshIaGpvkxERERUXaX6UvPiYiIiHKSTE9QFkJgy5YtOHToEJ4/f47k5GSt/UFBQZI1R0RERJRVmQ47w4YNw9KlS1G7dm3Y2tpCpVLJ0RcRERGRJDIddtauXYugoCA0btxYjn6IiIiIJJXpOTtWVlZwdXWVoxciIiIiyWU67EyePBlTpkzB27dv5eiHiIiISFKZPo3Vvn17rF+/HgUKFICzszMMDQ219l+8eFGy5oiIiIiyKtNhp1u3brhw4QK6dOnCCcpERESU7WU67OzcuRN79uxBtWrV5OiHiIiISFKZnrPj4OAAS0tLOXohIiIiklymw87cuXMxZswYPHz4UIZ2iIiIiKSV6dNYXbp0QVxcHAoXLgxTU9NUE5RfvXolWXNEREREWZXpsLNgwQIZ2iAiIiKSx1ddjUVERESUU/Cu50RERKRoDDtERESkaDkq7MyePRsqlQrDhg3TbIuPj8fAgQORL18+mJubo02bNoiIiNBfk0RERJStZCjsXL16FcnJyXL38lnnzp3D0qVL4eXlpbV9+PDh2LFjBzZv3owjR47g6dOnaN26tZ66JCIiouwmQ2GndOnSePHiBQDA1dUVL1++lLWpT8XExKBz585Yvnw58uTJo9keFRWFlStXYt68eahTpw7Kli2L1atX4+TJkzh9+rROeyQiIqLsKUNhx9raGqGhoQCAhw8f6nyUZ+DAgWjSpAnq1auntf3ChQtITEzU2l68eHE4Ojri1KlT6R4vISEB0dHRWg8iIiJSpgxdet6mTRvUrFkTBQsWhEqlQrly5WBgYJDmc0NCQiRtcMOGDbh48SLOnTuXal94eDhy584Na2trre22trYIDw9P95izZs3ClClTJO2TiIiIsqcMhZ1ly5ahdevWuH//PoYMGYLevXvDwsJC7t4QFhaGoUOHYt++fTA2NpbsuOPHj8eIESM0n0dHR8PBwUGy4xMREVH2keFFBRs2bAjgw6mjoUOH6iTsXLhwAc+fP0eZMmU025KSknD06FEsXLgQe/bswbt37xAZGak1uhMREQE7O7t0j2tkZAQjIyM5WyciIqJsItMrKK9evVrz8b///gsAKFSokHQdfaRu3bq4du2a1rYePXqgePHiGDt2LBwcHGBoaIgDBw6gTZs2AIA7d+7g8ePHqFy5siw9ERERUc6S6bCTnJyM6dOnY+7cuYiJiQEAWFhYYOTIkfjpp5+gVku3dI+FhQVKliyptc3MzAz58uXTbO/VqxdGjBiBvHnzwtLSEoMHD0blypVRqVIlyfogIiKinCvTYeenn37CypUrMXv2bFStWhUAcPz4cUyePBnx8fGYMWOG5E1+zvz586FWq9GmTRskJCTAx8cHixcv1mkPRERElH2phBAiM19gb28Pf39/NG/eXGv7X3/9hQEDBuDJkyeSNqgL0dHRsLKyQlRUFCwtLSU77sWLQNmywJ49L+Dl9V6y437s6tVc8PHJjwsXgI+mNhERESleRv9+Z/qc06tXr1C8ePFU24sXL45Xr15l9nBEREREssp02PH29sbChQtTbV+4cCG8vb0laYqIiIhIKpmeszNnzhw0adIE+/fv11zxdOrUKYSFhWHXrl2SN0hERESUFZke2alZsybu3r2LVq1aITIyEpGRkWjdujXu3LmD6tWry9EjERER0VfL9MgO8GGSsq6vuiIiIiL6GtItikNERESUDTHsEBERkaIx7BAREZGiMewQERGRon3VBOUUL168wJkzZ5CUlITy5cujYMGCUvVFREREJImvDjtbt25Fr169ULRoUSQmJuLOnTtYtGgRevToIWV/RERERFmS4dNYKXc4TzFlyhScPXsWZ8+exaVLl7B582b89NNPkjdIRERElBUZDjtly5bFX3/9pfk8V65ceP78uebziIgI5M6dW9ruiIiIiLIow6ex9uzZg4EDByIgIACLFi3C//73P3z//fdISkrC+/fvoVarERAQIGOrRERERJmX4bDj7OyMnTt3Yv369ahZsyaGDBmC+/fv4/79+0hKSkLx4sVhbGwsZ69EREREmZbpS887duyIc+fO4cqVK6hVqxaSk5NRqlQpBh0iIiLKljJ1NdauXbtw69YteHt7Y8WKFThy5Ag6d+6MRo0aYerUqTAxMZGrTyIiIqKvkuGRnZEjR6JHjx44d+4c+vbti2nTpqFmzZq4ePEijI2NUbp0aezevVvOXomIiIgyLcNhJyAgALt27cKGDRtw7tw5rF27FgCQO3duTJs2DUFBQZg5c6ZsjRIRERF9jQyHHTMzM4SGhgIAwsLCUs3RcXd3x7Fjx6TtjoiIiCiLMhx2Zs2aha5du8Le3h41a9bEtGnT5OyLiIiISBIZnqDcuXNnNGzYECEhIXBzc4O1tbWMbRERERFJI1NXY+XLlw/58uWTqxciIiIiyWV6nR0iIiKinIRhh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBQtW4edWbNmoXz58rCwsECBAgXQsmVL3LlzR+s58fHxGDhwIPLlywdzc3O0adMGEREReuqYiIiIsptsHXaOHDmCgQMH4vTp09i3bx8SExPRoEEDxMbGap4zfPhw7NixA5s3b8aRI0fw9OlTtG7dWo9dExERUXaSS98NfE5wcLDW5wEBAShQoAAuXLiAGjVqICoqCitXrkRgYCDq1KkDAFi9ejVKlCiB06dPo1KlSmkeNyEhAQkJCZrPo6Oj5fsmiIiISK+y9cjOp6KiogAAefPmBQBcuHABiYmJqFevnuY5xYsXh6OjI06dOpXucWbNmgUrKyvNw8HBQd7GiYiISG9yTNhJTk7GsGHDULVqVZQsWRIAEB4ejty5c8Pa2lrruba2tggPD0/3WOPHj0dUVJTmERYWJmfrREREpEfZ+jTWxwYOHIjr16/j+PHjWT6WkZERjIyMJOiKiIiIsrscEXYGDRqEf/75B0ePHkWhQoU02+3s7PDu3TtERkZqje5ERETAzs5OD51mL48fAy9eyHf8/PkBR0f5jk9ERCSFbB12hBAYPHgwtm3bhsOHD8PFxUVrf9myZWFoaIgDBw6gTZs2AIA7d+7g8ePHqFy5sj5azjYePwZKlBCIi1PJVsPUVODWLRUDDxERZWvZOuwMHDgQgYGB+Ouvv2BhYaGZh2NlZQUTExNYWVmhV69eGDFiBPLmzQtLS0sMHjwYlStXTvdKrG/FixdAXJwKCxdGws3tveTHv3cvFwYNssaLFxzdISKi7C1bh50lS5YAAGrVqqW1ffXq1ejevTsAYP78+VCr1WjTpg0SEhLg4+ODxYsX67jT7MvN7T28vKQPO0RERDlFtg47QogvPsfY2BiLFi3CokWLdNARERER5TQ55tJzIiIioq/BsENERESKxrBDREREisawQ0RERIrGsENERESKlq2vxqKcSe6VmwGu3kxERBnHsEOS0sXKzQBXbyYiooxj2CFJyb1yM8DVm4mIKHMYdkgWXLmZiIiyC05QJiIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRVNM2Fm0aBGcnZ1hbGyMihUr4uzZs/puiYiIiLIBRYSdjRs3YsSIEfj5559x8eJFeHt7w8fHB8+fP9d3a0RERKRnigg78+bNQ+/evdGjRw+4u7vD398fpqamWLVqlb5bIyIiIj3Lpe8Gsurdu3e4cOECxo8fr9mmVqtRr149nDp1Ks2vSUhIQEJCgubzqKgoAEB0dLSkvcXEfPjv1atxiI1NkvTYKR48MAAQjZgY4OP25a6tr7qfqw0A4eEfHnKxs/vw+JS+6uqztlLr6rM2v2fd1dVnbX7P0kn5uy2E+PwTRQ735MkTAUCcPHlSa/vo0aNFhQoV0vyan3/+WQDggw8++OCDDz4U8AgLC/tsVsjxIztfY/z48RgxYoTm8+TkZLx69Qr58uWDSqXSW1/R0dFwcHBAWFgYLC0tv4na/J75PSu1Nr9nfs9KrKvv2p8SQuDNmzewt7f/7PNyfNjJnz8/DAwMEBERobU9IiICdumMmRkZGcHIyEhrm7W1tVwtZpqlpaXeXkD6qs3v+duoze/526jN71n5dfVd+2NWVlZffE6On6CcO3dulC1bFgcOHNBsS05OxoEDB1C5cmU9dkZERETZQY4f2QGAESNGoFu3bihXrhwqVKiABQsWIDY2Fj169NB3a0RERKRnigg733//Pf777z/4+voiPDwcpUqVQnBwMGxtbfXdWqYYGRnh559/TnWKTcm1+T3rFr9n5dfVZ21+z8qvq+/aX0slxJeu1yIiIiLKuXL8nB0iIiKiz2HYISIiIkVj2CEiIiJFY9ghIiIiRWPYIVKo9+/fY82aNakW3CQi+tYw7JDOHTt2DF26dEHlypXx5MkTAMDatWtx/PhxPXemLLly5UK/fv0QHx+v71a+Kffv38eePXvw9u1bAPjyDQol8Pjx4zTrCCHw+PFjWWsnJSVhy5YtmDZtGqZNm4YtW7bg/fv3stZMsXbtWlStWhX29vZ49OgRAGDBggX466+/ZKu5evVqxMXFyXb87OTVq1fo1asXGjRogI0bN+q7nSxRxDo79PXOnz+PW7duAQBKlCiBcuXKyVpv69at+OGHH9C5c2dcunRJc/f5qKgozJw5E7t27ZKt9vv37zFz5kz07NkThQoVkq1OCj8/vww/d8iQIbL0UKFCBVy+fBlOTk6yHD+7io2NhZmZmU5rvnz5Et9//z0OHjwIlUqFe/fuwdXVFb169UKePHkwd+5c2Wq7uLjg2bNnKFCggNb2V69ewcXFBUlJSbLUvXHjBpo3b47w8HAUK1YMAPDLL7/AxsYGO3bsQMmSJWWpCwBLliyBr68vhg0bhhkzZmi+R2trayxYsAAtWrSQpe64ceMwdOhQtGvXDr169UKVKlVkqZMd9O3bF9euXYOPjw/69euHp0+fYvjw4fpu6+tIcONxyoKjR4+KdevWiVevXum0blhYmKhWrZpQqVQiT548Ik+ePEKlUomqVat+8e6xWVGqVCnxxx9/CCGEMDc3Fw8ePBBCCHHx4kVha2srW90U5ubmIjQ0VPY6Qgjh7Oys9TAzM0v18zYzMxMuLi6y9bBx40bh6uoqfv/9d3Hy5Elx5coVrYcuvH79WuzZs0esXbtW/PHHH1oPuZiZmYkePXqIY8eOyVbjUz/88IPw8fERYWFhWq/t4OBg4e7uLmttlUolnj9/nmr7w4cPhampqWx1K1WqJJo1a6b1++vVq1eiefPmonLlyrLVFUKIEiVKiG3btgkhtH+XXLt2TeTLl0+2uomJiSIoKEg0b95cGBoaimLFionZs2eLZ8+eyVZTCCHu3r0rOnToIKKiolLti4yMFB07dtT8DKRibW0tzp49K4QQ4vLlyyJv3ryiU6dOYsqUKeLZs2di0aJFYsqUKZLWlAvDjh7Nnz9fqNVqYW1tLb777jtx69YtndX28fERFStWFLdv39Zsu337tqhcubLw8fGRra6JiYkmbHz8C+rBgwfCyMhItropmjdvLgICAmSv86l169aJqlWrpvp5V69eXfz555+y1VWpVKkearVa81+5/f3338LCwkKoVCphZWUlrK2tNY88efLIVnfbtm2iRYsWwtDQULi5uYlZs2aJJ0+eyFZPCCFsbW3F5cuXhRCpX9tmZmay1Bw+fLgYPny4UKvVom/fvprPhw8fLoYMGSIqVqwoqlSpIkttIYQwNjYW169fT7X92rVrwtjYWLa6KbUfPnwohND+ed+9e1f22inCw8PFb7/9Jjw9PYWhoaFo1qyZ2L59u0hKSpK8Vu/evcXo0aPT3T9mzBjRr18/SWsWKFBA3Lx5U/P5lStXROPGjUWZMmXErVu3RN26dWV9syYlhh09cnJyEitWrBBCCOHr6ysKFiwo9u3bJx49eiQSExPF06dPxaNHj2SpbWxsLC5evJhq+/nz54WJiYksNYUQwsXFRezbt08Iof0L6o8//hAlSpSQrW6KJUuWCDs7OzFy5EgRGBgo/vrrL62HXFxdXdP9eTs7O8tW9+HDh599yM3NzU0MHTpUxMbGyl4rLc+fPxdz584Vnp6eIleuXKJJkyZi69atIjExUfJa5ubm4u7du5qPU17b586dE3nz5pW8nhBC1KpVS9SqVUuoVCpRpUoVzee1atUSDRo0EH369NH0JAcvLy9x4MCBVNsPHDggSpYsKVtdIT6M7Gzfvl0Iof3z9vPzE6VLl5a19sdOnz4t+vTpI4yMjISzs7OwsrISzs7O4tChQ5LWKVq0qGaUJS3nz58XRYsWlbRmq1atxNy5cyU9pr4w7OiRmZmZ1imVKVOmCLVaLdRqtbhw4YIoXry4bO++3dzcxJkzZ1JtP3PmjChcuLAsNYUQYubMmcLd3V2cPn1aWFhYiGPHjok///xT2NjYCD8/P9nqpkhrpOPjEQ+5mJiYpPmL6syZM7KGS30zNTWVfGj9a/n5+QkjIyOhUqmEjY2NmDRpkqQhrFGjRmLixIlCiA9/fENCQkRSUpJo166daNOmjWR10tK9e/c0T2/IbefOncLDw0Ns3rxZhIWFibCwMLF582bh6ekpdu7cKaKiojQPqS1fvlx89913YsOGDcLMzEysX79eTJ8+XfOxnMLDw8Wvv/4q3N3dhbGxsejQoYPmTVxMTIwYM2aMcHR0lLTmxyNZaXn48KHkv0uuXr0qFi1aJOkx9YVhR4/Kli0r/v77b61tERER4sqVK+Lt27fi7Nmz4vDhw7LU3r59u6hQoYI4d+6cZtu5c+dEpUqVNOfB5ZCcnKz5hZQSMoyNjTV/JJSqadOmonTp0uLChQuabefPnxdlypQRzZo1k73+jRs3xO7du3U2kpWiVatWYuPGjbLXSU94eLj45ZdfRIkSJYSpqano3LmzOHjwoFizZo3w8PAQ9evXl6zWtWvXRIECBUTDhg1F7ty5Rdu2bUWJEiWEra2tuH//vmR1spNP3yyknCL99HO53kj8+eefokiRIpqa3333nWa0XC5NmzYVhoaGwsPDQ8yfP1+8fPky1XMiIiKESqWStK6trW2ao2gp9u/fr5N5jzkVbwSqR6tWrcKhQ4ewdu1andfOkycP4uLi8P79e+TK9eGivJSPP72K5dWrV5LXf/fuHe7fv4+YmBi4u7vD3Nxc8hpfEh8fD2NjY53U+u+//9CtWzcEBwfD0NAQwIeft4+PDwICAlJdRSOVkJAQtGrVCteuXYNKpdJcnqxSqQBAlqt0/v77b83H//33H6ZOnYoePXrA09NT872naN68ueT1ASAoKAirV6/Gnj174O7ujh9//BFdunSBtbW15jkPHjxAiRIl8O7dO8nqRkVFYeHChbhy5QpiYmJQpkwZDBw4EAULFpSsRlpiY2Mxe/ZsHDhwAM+fP0dycrLW/pCQEFnqHjlyJMPPrVmzpiw9AEBcXBxiYmJk+3f0sV69euHHH39E5cqV032O+L9L/qW8CrJ9+/ZITEzEtm3b0tzfokUL5M6dG5s3b5ak3tWrVzP8XC8vL0lqyolh5xv1xx9/ZPi53bp1k6xuz5498b///Q8WFhZa22NjYzF48GCsWrVKslppSUpKwsyZM+Hv74+IiAjcvXsXrq6umDRpEpydndGrVy/JawohEBYWBhsbG/z777+aS/2LFy+OokWLSl7vY82aNYOBgQFWrFgBFxcXnD17Fi9fvsTIkSPx22+/oXr16pLXVKsztnyXSqWS7ZJoKysrdOjQAT/++CPKly+f5nPevn2LOXPm4Oeff5alB13q2LEjjhw5gh9++AEFCxbUhNkUQ4cO1VNnyrNmzRp8//33MDIy0tr+7t07bNiwAV27dpWl7qVLl1C5cmU0bdoUY8aM0Vzqf/v2bcyZMwc7d+7EyZMnUaZMGUnqqdVqzRukT19Pn5Lr37GUGHaygbdv30IIAVNTUwDAo0ePsG3bNpQoUQI+Pj567k5aBgYGaa4H8uLFC9jZ2cm+GNnUqVPxxx9/YOrUqejduzeuX78OV1dXbNy4EQsWLMCpU6ckr5mcnAxjY2PcuHEDbm5ukh//c/Lnz4+DBw/Cy8sLVlZWOHv2LIoVK4aDBw9i5MiRuHTpkk770ZW4uDjNvyddio+Px9WrV9McXZFrFAv4sLbMzp07UbVqVdlqpLh69SpKliwJtVr9xXf/cr7jf/nyJXx9fXHo0KE0f95yjEgD6f8Oe/nyJQoUKCDrH/5//vkHPXv2xMuXL7W258uXDytWrJD0NZaySCPwIWiNGjUKo0eP1oxonTp1CnPnzsWcOXPQsmVLyerKhYsKZgMtWrRA69at0a9fP0RGRqJixYowNDTEixcvMG/ePPTv31+SOtHR0bC0tNR8/Dkpz5NKdHQ0xIc5Ynjz5o3W6aOkpCTs2rVLJ0PQa9aswbJly1C3bl3069dPs93b2xu3b9+WpaZarYabmxtevnyp87CTlJSkGUXLnz8/nj59imLFisHJyQl37tyRvb6+3gV/HHTi4+NTnaqS+vUNAMHBwejatStevHiRap+co1jAh9PSefPmle34HytVqhTCw8NRoEABlCpVSuv06Mfk/p5/+OEH3L9/H7169YKtre0XRx+kkt5Ix7///gsrKytZazdt2hSPHj1CcHAw7t+/DyEEihYtigYNGkge7j8+BdeuXTv4+fmhcePGmm1eXl5wcHDApEmTckTY4QTlbCBfvnyatSqWL18uvLy8RFJSkti0aZMoXry4ZHXUarWIiIgQQgitCYQfP+SaTJhevZSHgYGBmD59uuR1P5Xe2hw3btyQbS0UIT6sN1OtWjVx7do12WqkpVq1apoJ5x07dhQNGzYUx48fF127dhUeHh6y1//4NfexFy9eyHr1W0xMjBg4cKCwsbFJ8/UmhyJFiogBAwaI8PBwWY7/OWvXrhVt27bVySX+Dx8+FMnJyZqP9bW0gbm5uWZdI10oVaqUKF26tFCr1cLT01OULl1a8/Dy8hIWFhaiXbt2OutHl4yNjbXW20lx8+ZNna1plFUc2ckG4uLiNO++9+7di9atW0OtVqNSpUpaQ4lZdfDgQc27v5Ql7XXl0KFDEEKgTp062Lp1q9a70Ny5c8PJyQn29vay9+Hu7o5jx46lmji4ZcsWlC5dWra6Xbt2RVxcHLy9vZE7d26YmJho7ZdryH3ixImIjY0F8OEUXtOmTVG9enXky5dPJ/e6EXp6FzxmzBgcOnQIS5YswQ8//IBFixbhyZMnWLp0KWbPni1LzYiICIwYMQK2trayHP9z5s6diwcPHsDW1hbOzs6pJoJfvHhRslof/9vR521Iihcvrrn/mC6kjF5cvnwZPj4+WhdV5M6dG87OzmjTpo1s9Q8ePIhBgwbh9OnTqUYmo6KiUKVKFfj7+8syD69EiRKYNWsWVqxYgdy5cwP4MDo7a9YslChRQvJ6cmDYyQaKFCmC7du3o1WrVtizZ4/m3iPPnz+XdLi9Zs2aqFu3LgYOHIjWrVun+ZwXL16gQoUKkl+9kXIlRmhoKBwcHDI8iVVqvr6+6NatG548eYLk5GQEBQXhzp07WLNmDf755x/Z6i5YsEC2Y3/Ox3O+ihQpgtu3b+PVq1fIkyePrGG3dOnSUKlUUKlUqFu3ruaKP+DDqbXQ0FA0bNhQtvo7duzAmjVrUKtWLfTo0QPVq1dHkSJF4OTkhHXr1qFz586S12zbti0OHz6MwoULS37sL9HnaYR79+6lO2/G19dXtrqLFy/GuHHj4Ovri5IlS6YKeFKfqkyZyO7s7Izvv/9eZ1dypliwYAF69+6d5vdlZWWFvn37Yt68ebKEHX9/fzRr1gyFChXSzMO6evUqVCoVduzYIXk9OXCCcjawZcsWdOrUCUlJSahbty727t0LAJg1axaOHj2K3bt3S1ZLrVZDrVbjp59+wpQpU1Ltj4iIgL29veyz6+Pi4vD48eNUcyl0cQnjsWPHMHXqVK3Lg319fdGgQQPZa+vL/fv38eDBA9SoUQMmJiYZusIiK1JeW1OmTMHIkSPTfRec8i5Raubm5rh58yYcHR1RqFAhBAUFoUKFCggNDYWnpydiYmIkrxkXF4d27drBxsYmzcvs5brZqz4tX74c/fv3R/78+WFnZ6f1mlKpVJKOKH3q3r176NSpU6oaKa/tnHCFUGY4OTkhODg43ZGU27dvo0GDBrLd5T42Nhbr1q3TzG0sUaIEOnXqpPMb7n4thp1sIjw8HM+ePYO3t7dm1OPs2bOwtLRE8eLFJaujVquxdOlSjBo1CnXq1MGff/6p9WKVO+z8999/6NGjR7oBTmm/oNKiqwmzwIcrRNq3b49Dhw5p3Ym7Z8+est+JG/iwxIE+3gV7eXnh999/R82aNVGvXj2UKlUKv/32G/z8/DBnzhz8+++/ktdcuXIl+vXrB2NjY+TLly/VH3651rrRJycnJwwYMABjx47Vee0KFSogV65cGDp0aJoTlKVc1ydv3ry4e/cu8ufP/8VRUblOSRsbG+P69esoUqRImvvv378PT09PnZ7ay0l4GkvPEhMTYWJigsuXL6eaM1KhQgVZarZo0QLVqlVDixYtUKlSJfz1119wdXWVpdanhg0bhsjISJw5cwa1atXCtm3bEBERgenTp8v+hxcAwsLCoFKpUKhQIQAfAmVgYCDc3d3Rp08f2erGxsZi7Nix2LRpU6rLRgH5Qt7w4cNhaGiIx48fa70j/P777zFixAjZf+YpazS9e/cuzdMcjo6OstTt0aMHrly5gpo1a2LcuHFo1qwZFi5ciMTERMybN0+WmimjpePGjdP5adqUNVHSI9fr6/Xr12jXrp0sx/6S69ev49KlS5r1ZuQ0f/58zbzK+fPn63S+Y4rvvvvus2Hn6tWrsi1euWbNms/ul+uqSknpb240pXBxcdHZVQUqlUpzdUxkZKRo1KiRyJs3r+a+LuHh4bJeJWNnZ6e5J5eFhYW4c+eOEEKIv/76S1StWlW2uimqVasm1qxZI4QQ4tmzZ8LCwkJUrlxZ5M+fX0yZMkW2ugMGDBAlSpQQW7ZsESYmJmLVqlVi2rRpolChQrLe9Vwfd+L+2N27d0W1atV0dtVfeh4+fCi2bt0qrly5IluNPHny6O22ENu3b9d6bN68WUyYMEH22yf07NlTLFmyRLbjf0716tU1v7e+BYMGDRIlS5YUb9++TbUvLi5OlCxZUgwePFiW2tbW1lqPlNv9GBkZiTx58shSU2oc2ckGfvrpJ0yYMAFr167V2VoZwIdJbTt37sT48ePRuHFj/PLLL+jUqZOsNWNjYzXr6eTJkwf//fcfihYtCk9PT1nP76e4fv26ZsRs06ZN8PT0xIkTJ7B3717069dPtgmV+pgwC3z4eae1/sarV69SrX0jh+7duyNXrlz4559/0lzZVw7JyckICAhAUFAQHj58CJVKBRcXF7Rt2xaenp6y1e3WrRs2btyICRMmyFYjPS1atEi1rW3btvDw8MDGjRslXRncz89P83GRIkUwadIknD59WufzlAYPHoyhQ4di9OjRadaWev7f06dPMW/ePPj6+qZ5NdT06dMxatQo2a7GmzhxIoKCglC0aFEMGjRIawXlRYsWISkpCT/99JMstV+/fp1q271799C/f3+MHj1alppS45ydbKB06dK4f/8+EhMT4eTklGrCl5QhIL3VPzds2IAff/wRtWvXxq5du2Qb9i5fvjymT58OHx8fNG/eHNbW1pg1axb8/PywZcsWPHjwQJa6KczNzXH9+nU4OzujefPmqFq1KsaOHYvHjx+jWLFisp3v1vWE2adPn8Le3h6NGzdG2bJlMW3aNFhYWODq1atwcnJChw4dkJycjC1btkha91NmZma4cOGCpPPOPkcIgWbNmmHXrl3w9vZG8eLFIYTArVu3cO3aNTRv3hzbt2+XpfaQIUOwZs0aeHt7w8vLK9UfX7lOn31OSEgIvLy8JH19ubi4ZOh5cs9TSutU4ce3N5D6d9ioUaMQHR2NZcuWpbm/X79+sLKywi+//CJp3Y89fPgQAwYMwJ49e7Tuc+fj44NFixZl+P+NVM6fP48uXbrItiCrlDiykw3o8rLR9LJthw4dULx4cdl7GTp0KJ49ewbgw6WcDRs2xLp165A7d24EBATIWhsAPDw84O/vjyZNmmDfvn2YNm0agA/hIF++fLLVdXV1RWhoKBwdHVG8eHFs2rQJFSpUwI4dO7RuTikVDw8PLFq0CL/++ivq1KmD8+fP4927dxgzZgxu3LiBV69e4cSJE5LX/ZS7u3uaKwrLJSAgAEePHsWBAwdQu3ZtrX0HDx5Ey5YtsWbNGlnmGFy7dk0z7+769eta+/Qxx+Pt27fw8/PDd999J+lxQ0NDJT3e19J1H8HBwfD39093f9euXdG7d29Zw46zszN27dqF169fa1ZQdnNzQ548eWSr+Tm5cuXC06dP9VI7sziy8405cuQIqlatqrXuycdevnyJnTt36mzCWVxcHG7fvg1HR0fkz59f9nqHDx9Gq1atEBUVhe7du2tuPDphwgTcvn0bQUFBstSdP38+DAwMMGTIEOzfvx/NmjWDEALv3r3D/PnzJb9R4+LFizF27Fg0bNgQ/v7+8Pf31/mduIEPAWPixImYOXNmmqcapL4KrUGDBqhTpw7GjRuX5v6ZM2fiyJEj2LNnj6R19e3TK4TE/92WxdTUFH/++acs9+WKjo6Gubl5qhGW5ORkxMTEyHaFob6YmZnh1q1b6U6qT7kIIGURT6n17NkzQ8+T42bKf//9t9bnQgg8e/YMCxcuhIODg6TLo8iFYScbuXDhguaO2B4eHrKu6KsvU6dOxahRo1LNI3n79i1+/fVXWRchS5GUlITo6Gitd0MPHz6EqampTu7PBXy4yd6FCxfg5uYm2zyS0NBQ9OrVCzdv3sSyZctkvRFlelL+EH46siHXqQY7OzsEBwejVKlSae6/dOkSGjVqhPDwcEnr6tsff/yh9blarYaNjQ0qVqwoy7v+bdu2YezYsbh8+XKqf8uxsbEoU6YMfvvtNzRr1kzy2p+6efNmmmt2Sf16z58/P4KCglCjRo009x89ehStW7eWbSRTrVbDyckJpUuXTneEHvjw/0aO2h9TqVSwsbFBnTp1MHfuXJ28ccoqhp1s4Pnz5+jQoQMOHz6sOaURGRmJ2rVrY8OGDbCxsdFvgxLS1x2D01sbw8rKCkWLFsWoUaNQv359yevqc4n3FAsXLsTw4cNRokSJVCN6ck8KP3LkyGf3S7kWCvBhwcJHjx6l+8v36dOncHFxQUJCgiT1WrdujYCAAFhaWqa7KnkKuUYN9aFBgwZo3749fvzxxzT3r1q1Chs3bpR1BC0kJAStWrXCtWvXtG5GmvLvXOrfJU2aNIG9vT2WL1+e5v4ff/wRT58+xa5duyStm2LgwIFYv349nJyc0KNHD3Tp0kWnF7TkdJyzkw0MHjwYb968wY0bNzRrody8eRPdunXDkCFDsH79ej13KB2Rzsq9V65ckfUfbnq3a4iMjMSFCxfQtGlTbNmyRfJ3ovpc4h34MIIUFBSEPHnyoEWLFumevpSL1GHmS5KSkj77PRoYGOD9+/eS1bOystK8nuW+4/WXREZGYuXKlVqjwz179pSlr+vXr2Px4sXp7q9RowYmTpwoed2PDR06FC4uLjhw4ABcXFxw9uxZvHz5EiNHjsRvv/0meb2UN0RWVlYYPXq05qqriIgIzJkzBwEBAZrV7+WwaNEizJs3D0FBQVi1ahXGjx+PJk2aoFevXmjQoIFe5oXlJBzZyQasrKywf/9+lC9fXmv72bNn0aBBA0RGRuqnMQmljKxERUXB0tJS6x9mUlISYmJi0K9fPyxatEgv/c2bNw9btmzByZMnJT2uPpd4X758OUaOHIl69eph6dKlehsh1OUfYbVajUaNGqV7WX1CQgKCg4Mlfdef3qlZXTp//jx8fHxgYmKiWVrh3LlzePv2Lfbu3YsyZcpIWs/ExASXLl1K9yq7W7duoUyZMrKu5ps/f34cPHgQXl5esLKywtmzZ1GsWDEcPHgQI0eOxKVLlySvuXTpUgwdOhSJiYma32NRUVEwNDTE/Pnz0b9/f8lrpufRo0cICAjAmjVr8P79e9y4cUPrtixS+/fff/H333+necpQH1caZhZHdrKB5OTkVBM3AcDQ0DDVirM51YIFCyCEQM+ePTFlyhStP3Qp90qqXLmy3vpr2rQppk+fLvlxIyIi0vx/myJXrlz477//JK/bsGFDnD17FgsXLtTr6qZp/RGeN28eZsyYIcsf4ZQVmz9H6p/HlClT0K9fP72GneHDh6N58+ZYvny5ZmTr/fv3+PHHHzFs2DAcPXpU0nrOzs44f/58umHn/Pnzst8RPSkpSbOqcf78+fH06VMUK1YMTk5OuHPnjiw1+/bti6ZNm2LTpk2aq6GKFi2Ktm3balZl15WUVbOFELLfZufAgQNo3rw5XF1dcfv2bZQsWRIPHz6EEELyf8Oy0dHihfQZzZs3FzVq1BBPnjzRbPv3339FzZo1RcuWLfXYmfQOHz4sEhMT9d1GKlevXhW2traSH9fV1VVs27Yt3f1bt24VLi4uktetV6+eCAsLk/y4mVWtWjXRvXt3rf/niYmJolu3bqJ69ep67Ew6H69Kri/Gxsbi1q1bqbbfuHFDmJiYSF5vwoQJwtHRUYSHh6fa9+zZM+Ho6CgmTJgged2PVatWTfNvq2PHjqJhw4bi+PHjomvXrsLDw0PW2voSHx8vAgMDRb169YSxsbFo27at2Llzp0hKSpK1bvny5YWvr68Q4v+vxP7mzRvRvHlzsXjxYllrS4VhJxt4/PixKFWqlDA0NBSurq7C1dVVGBoaitKlS2eLP1hSSExMFPHx8VrbwsPDxeTJk8Xo0aPFsWPH9NTZB0OHDhU+Pj6SH1efS7xnB7r+I6wPKpVKPH/+XK89FChQQOzZsyfV9uDgYFGgQAHJ60VHRwsPDw9hYWEh+vfvLxYsWCAWLFgg+vXrJywsLIS7u7uIjo6WvO7HgoODxdatW4UQQty7d08UK1ZMqFQqkT9/fnHgwAFZa+tD//79RZ48eYSXl5dYsGCB+O+//3RW29zcXHMrFGtra3H9+nUhhBCXL18WTk5OOusjKzhnJ5sQQmD//v2alShLlCiBevXq6bkr6fTo0QO5c+fG0qVLAQBv3ryBh4cH4uPjUbBgQdy8eRN//fUXGjduLEv9ESNGpLk9KioKFy9exN27d3H06FGULVtW0roREREoU6YMDAwM0l3i/eLFi7ItMa9vtra2WLt2LRo0aKC1fc+ePejatSsiIiL01Jl01Gq11kTl9Mh1N2zgw+rN27Ztw2+//YYqVaoAAE6cOIHRo0ejTZs26U7Qz4qoqCiMHz8eGzdu1NxOwNraGh06dMCMGTP0stDdq1evvnhX8pxKrVbD0dERpUuX/uz3J8dVf3Z2djh06BBKlCgBd3d3zJ49G82bN8eVK1dQtWpVyVeAlwPn7OjZx3c9r1+/viyXP2cHJ06cwMKFCzWfr1mzBklJSbh37x6srKwwduxY/Prrr7KFnfQmK1paWqJ+/foICgqSZal1W1tbnDx5Ev3798f48ePTXOJdqUEH+HB39V69eqX5R7hjx4567k46n85D07XffvsNKpUKXbt21VxtZmhoiP79+2P27Nmy1LSyssLixYuxaNEivHjxAkII2NjY6DVoKPlS7K5du+rtZ1upUiUcP34cJUqUQOPGjTFy5Ehcu3YNQUFBqFSpkl56yiyO7GQDrq6u2LZtG7y9vfXdimzMzMxw/fp1TaBo3bo1ChUqpLmp4M2bN1GrVi08f/5cn23KKrss8a5L7969w+jRo+Hv74/3799DCIHcuXNr/gjr4makclOr1QgPD9fZgpSfExcXp7m/XOHChfU6aVouGVlJWKVSYeXKlTro5tsQEhKCmJgYeHl5ITY2FiNHjsTJkyfh5uaGefPmyT4ZXQoMO9nAypUrERQUpPO7nutSvnz5cOzYMbi7uwMA7O3t8euvv2ru9h0SEoKSJUsiLi5On22STJT8Rzi9hTJJHq1atUp3X1JSEvbv34+EhATZrlBydXXFuXPnUt1LLzIyEmXKlJH15qf6kJSUhBMnTsDLy0uW+/jpCk9jZQMLFy7E/fv3YW9vL/tdz/WlVKlSWLt2LWbNmoVjx44hIiICderU0ex/8OAB7O3t9dghSUmf9/HRtezwfjE+Ph6///47Dh06hOfPn6daskIJv0NSpHc7hL/++gsTJkyAkZGRrLedefjwYZpBKiEhAU+ePJGtrr4YGBigQYMGuHXrFsMOZY0u73quL76+vmjUqBE2bdqEZ8+eoXv37lpL+m/btg1Vq1bVY4ckpYCAgAzdx0cJssNaWL169cLevXvRtm1bVKhQQZETdNNz4sQJjBs3DhcvXsSgQYMwbtw4WU4Rf3wzzD179mjN0UpKSsKBAwfg7Owsed3soGTJkggJCZFlXqPO6OUaMNJITEwUU6ZMUcwl5p9z8+ZNsWDBArFhw4ZU60IsXbpUXLp0ST+NkeQGDBgg8uTJI0qVKiX+97//iZcvX+q7JUWztLQUx48f12sPaS2vIKcbN26Ipk2bily5comePXvK/jtUpVIJlUol1Gq15uOUR+7cuUXRokXFjh07ZO1BX3bv3i1KlSolduzYIZ4+fSqioqK0HjkBw042YG5uLkJDQ/XdBpGkPl4AzdTUVLRr104EBweL5ORkfbemOCVKlBBXrlzRed2kpCQxdepUYW9vLwwMDMSDBw+EEEJMnDhRrFixQpaajx8/Ft27dxe5cuUSLVu2FDdv3pSlTnqcnZ11usZNdvBxsFOr1ZpHyuc5AScoZwMtWrRA69atM7TUPVFOpOv7+Hxrdu/eDT8/P/j7++v0ypipU6fijz/+wNSpU9G7d29cv34drq6u2LhxIxYsWIBTp05JXtPU1BQqlQqDBg367Knv5s2bS177W3XkyJHP7tf1DX+/BufsZAONGjXCuHHjcO3aNZQtWzbVBGX+o6WcTpf38fkWlStXDvHx8XB1dYWpqWmq+7HJtaDhmjVrsGzZMtStWxf9+vXTbPf29tYskCq1+Ph4AMCvv/6KX3/9Nc3nqFQqWV9nBw4cwIEDB9KcDK6ESfcpunbtikWLFmnCzJUrV+Du7v7Z+/1lVxzZyQbUanW6++T+R0skl4SEBAQFBWHVqlU4fvw4mjZtih49eqBhw4affc1T5tWrVw+PHz9Gr169YGtrm2qCslyjxiYmJrh9+zacnJxgYWGBK1euwNXVFTdv3kSFChVyxMq6mTVlyhRMnToV5cqVQ8GCBVP9rNO7Wiwn+nRZBUtLS1y+fBmurq567izzOLKTDWSHqzmIpDRgwABs2LABDg4O6NmzJ9avX4/8+fPruy3FOnnyJE6dOqXzhUnd3d1x7NixVKfOtmzZgtKlS+u0F13x9/dHQEAAfvjhB323IrtPx0Jy8tgIw44eNW7cGOvXr9dcwjh79mz069dPs5bBy5cvUb16ddy8eVOPXUrrW1uQ61vl7+8PR0dHuLq64siRI+me85fjPj7fouLFi+Pt27c6r+vr64tu3brhyZMnSE5ORlBQEO7cuYM1a9bgn3/+0Xk/uvDu3TvNrU8o5+BpLD360hBhREQE7O3tFXUaK72l9SMiIuDo6IiEhAQ9dUZS6t69e4bWelm9erUOulG+vXv3YsqUKZgxYwY8PT1TzamwtLSUrfaxY8cwdepUXLlyBTExMShTpgx8fX1T3fxVKcaOHQtzc3NMmjRJ363ITq1W4+DBg5qV/atUqYJNmzahUKFCWs/z8vLSR3uZwrCjR5/+4f/4nDegrLCTsiBXy5Yt8ccff6S5INe+fftw584dfbVIlGOlzIH6NGAKITjvT2JDhw7FmjVr4OXlBS8vr1TBct68eXrqTHofX1jwqZTtOeX1xdNYpBMpq0SrVKpUkyUNDQ3h7OyMuXPn6qEzopzv0KFD6e67du2abHXDwsKgUqk07/TPnj2LwMBAuLu7o0+fPrLV1aerV6+iVKlSAIDr169r7VPaytWhoaH6bkEyHNnRIwMDA4SHh8PGxgbAh5Gdq1evapbkVtLITgoXFxecO3eOk1WJZPTmzRusX78eK1aswIULF2T7HVK9enX06dMHP/zwA8LDw1G0aFGULFkS9+7dw+DBg2W9RxXn/1FmcGRHj4QQ6N69O4yMjAB8WD+iX79+mnV2lDh/RUnvFIiym6NHj2LlypXYunUr7O3t0bp1ayxatEi2etevX0eFChUAAJs2bYKnpydOnDiBvXv3ol+/frwhJ2UbDDt69OnpnC5duqR6TteuXXXVjs58KwtyEelCeHg4AgICsHLlSkRHR6N9+/ZISEjA9u3b4e7uLmvtxMREzZu1/fv3axZALV68OJ49eyZLzexwQ87z589j06ZNePz4Md69e6e1j1cYZk8MO3r0LV6J8qUFuYgo45o1a4ajR4+iSZMmWLBgARo2bAgDAwP4+/vrpL6Hhwf8/f3RpEkT7Nu3D9OmTQMAPH36NNXpJanoe/7fhg0b0LVrV/j4+GDv3r1o0KAB7t69i4iICLRq1Uq2upQ1nLNDOlWwYEHMmTPnm1iQi0huuXLlwpAhQ9C/f3+4ublpthsaGmqW9pfT4cOH0apVK0RHR6Nbt26akdkJEybg9u3bso5y6Gv+n5eXF/r27YuBAwdqrqB1cXFB3759UbBgQUyZMkWn/VDGMOyQTuXLlw9nz55F4cKF9d0KUY53+vRprFy5Ehs3bkSJEiXwww8/oEOHDihYsKBOwg7w4dRRdHQ08uTJo9n28OFDmJqaplpPSwnMzMxw48YNODs7I1++fDh8+DA8PT1x69Yt1KlTR7bTd/r09u1bCCFgamoK4MONfbdt2wZ3d/ccs54ST2ORTv34448IDAz8JhbkIpJbpUqVUKlSJSxYsAAbN27EqlWrMGLECCQnJ2Pfvn1wcHCAhYWFrD0YGBhoBR0Ass+ZSaGP+X958uTBmzdvAADfffcdrl+/Dk9PT0RGRiIuLk6WmvrWokULtG7dGv369UNkZCQqVqwIQ0NDvHjxAvPmzUP//v313eIXMeyQTsXHx2PZsmXYv3+/4hfkItIVMzMz9OzZEz179sSdO3ewcuVKzJ49G+PGjUP9+vW1JvVKIU+ePGnOt7OyskLRokUxatQo1K9fX9Kan9LX/L8aNWpg37598PT0RLt27TB06FAcPHgQ+/btQ926dXXSg65dvHgR8+fPB/Dhvme2tra4dOkStm7dCl9f3xwRdngai3Sqdu3a6e5TqVQ4ePCgDrshUq6kpCTs2LEDq1atkjzs/PHHH2luj4yMxIULF7Bx40Zs2bIFzZo1k7Tux/Q1/+/Vq1eIj4+Hvb09kpOTMWfOHJw8eRJubm6YOHFiqlEuJTA1NcXt27fh6OiI9u3bw8PDAz///DPCwsJQrFixHDGixbBDRESSmjdvHrZs2YKTJ0/KVoPz/3THy8sLP/74I1q1aoWSJUsiODgYlStXxoULF9CkSROEh4fru8UvYtghIiJJ3b17F5UqVcKrV69kq6HPG3ImJyfj/v37ac4VqlGjhs77kduWLVvQqVMnJCUloW7duti7dy8AYNasWTh69Ch2796t5w6/jHN2SOe4IBeRsiUkJCB37tyy1tDX/L/Tp0+jU6dOePToUaobZOaUm2JmVtu2bVGtWjU8e/YM3t7emu1169bNMWsLMeyQTnFBLiLlW7lypeZmmXLR1w05+/Xrh3LlymHnzp3f1MKodnZ2sLOz09qWcquQnICnsUinuCAXUc43YsSINLdHRUXh4sWLuHv3Lo4ePYqyZcvquDP5mZmZ4cqVKyhSpIi+W5Fd69atM/S8nDAiz5Ed0qkHDx6gSZMmAIDcuXMjNjYWKpUKw4cPR506dRh2iHKAS5cupbnd0tIS9evXR1BQEFxcXHTclW5UrFgR9+/f/ybCzsf3HcvpGHZIp77FBbmIlObQoUP6bgGA7ub/Xb16VfPx4MGDMXLkSISHh8PT0zPVXCEvLy/J6uqbku7fyLBDOvUtLshFRNLT5fy/UqVKQaVSaU1I7tmzp+bjlH1KnaCsBJyzQzr1LS7IRUTS0+X8v0ePHmX4uU5OTpLVJekw7BARUY7zLd6Qk74eT2ORzn1rC3IRkfT0Nf9v1qxZsLW11TqNBXy48eh///2HsWPHylabvh7DDunUt7ggFxFJT1/z/5YuXYrAwMBU2z08PNChQweGnWyKp7FIp0qVKoWiRYtiypQpaS7IpaRLHYlIPvqa/2dsbIxbt26lurQ+JCQE7u7uiI+Pl6UuZQ1Hdkin7t27hy1btnwTa1QQkXzy5s2r+VitVmPcuHE6qevg4IATJ06kCjsnTpyAvb29TnqgzGPYIZ36lhbkIiJ56WP+X+/evTFs2DAkJiaiTp06AIADBw5gzJgxGDlypCw1KesYdkh23+qCXEQkH33N/xs9ejRevnyJAQMGaBYyNDY2xtixYzF+/HhZalLWcc4OyU6tVqdakOtjXJCLiDJLH/P/kpKScOLECc0btVu3bsHExARubm4wMjKSvB5Jh2GHZMcFuYhIavq6IWd6E5Qpe+NpLJIdAwwRSU1f8/9KliyJkJAQhp0chiM7pFNckIuIvtbH8/8ePHiAiRMnYvTo0Tqd/xccHIzx48dj2rRpKFu2LMzMzLT2W1paylKXsoZhh3TK2dkZgYGBqFKlitb2M2fOoEOHDggNDdVTZ0SU3WWH+X9qtVqrXgrOO8zeeBqLdCo8PBwFCxZMtd3Gxob3siGiz8oOb4YOHTqk7xboKzDskE5xQS4i+lrZYf5fzZo19d0CfQX1l59CJJ2UBblWr16NR48e4dGjR1i1ahWGDx+O3r1767s9IsohZs2ahVWrVqXavmrVKvzyyy+y1j527Bi6dOmCKlWq4MmTJwCAtWvX4vjx47LWpa/HsEM6NXr0aPTq1QsDBgyAq6srXF1dMXjwYAwZMoQLchFRhi1duhTFixdPtd3DwwP+/v6y1d26dSt8fHxgYmKCixcvIiEhAQAQFRWFmTNnylaXsoYTlElnuCAXEUlFXzfkLF26NIYPH46uXbvCwsICV65cgaurKy5duoRGjRohPDxclrqUNRzZIZ0xMDBAgwYNEBkZCXNzc5QvXx4lS5Zk0CGiTEuZ//cpuef/3blzJ837bllZWSEyMlK2upQ1nKBMOsUFuYhICvq6IaednR3u378PZ2dnre3Hjx+Hq6urbHUpaxh2SKemT5+OUaNGcUEuIsoSfd2Qs3fv3hg6dChWrVoFlUqFp0+f4tSpUxg1ahQmTZokW13KGs7ZIZ3iglxElFX6nP8nhMDMmTMxa9YsxMXFAQCMjIw0b+Ioe2LYIZ06cuTIZ/dzDQsiygh935Dz3bt3uH//PmJiYuDu7g5zc3O99EEZw9NYpFMMM0QkBX3P/8udOzfc3d31UpsyjyM7pHPHjh3D0qVLERISgs2bN+O7777D2rVr4eLigmrVqum7PSLKAXR9Q85Pb16cnrQWOiT9Y9ghndq6dSt++OEHdO7cGWvXrsXNmzfh6uqKhQsXYteuXdi1a5e+WySiHEDX8//UajWcnJxQunTpdG9ECgDbtm2TtC5Jg2GHdIoLchGRFHQ9/2/gwIFYv349nJyc0KNHD3Tp0gV58+aVtAbJh2GHdMrU1BQ3b96Es7OzVtiRe9VTIqKsSkhIQFBQEFatWoWTJ0+iSZMm6NWrFxo0aKA1ukTZD1dQJp1KWZDrU1yQi4gyS9c35DQyMkLHjh2xb98+3Lx5Ex4eHhgwYACcnZ0RExMjS02SBsMO6VTKglxnzpzRLMi1bt06jBo1Cv3799d3e0SUQ+j7hpxqtRoqlQpCCK4PlgPwNBbpFBfkIiIp6GP+38ensY4fP46mTZuiR48eaNiwodaEacp+GHZIL7ggFxFlha7n/w0YMAAbNmyAg4MDevbsic6dOyN//vyS1iD5cFFB0gsuyEVEWaHrG3L6+/vD0dERrq6uOHLkSLpXgwUFBUlem7KOYYd0ggtyEZGUdH1Dzq5du/KKqxyMp7FIJ7ggFxFJifP/KDMYdkgnuCAXEcmB8/8oIxh2SGe4IBcREekDww7pxaNHjxAQEIA1a9bg/fv3uHHjBt+REdEXcf4ffQ1OUCa94IJcRPQ1AgICMjT/j+hjHNkhneGCXESUVZz/R1+DYYd0ggtyEZFUOP+PMothh3RCrVbD0dERpUuX/uwvIy7IRUSZwfl/lBGcs0M6wQW5iEgOnP9HGcGRHSIiylE4/48yiyM7RESUY3w6/2/9+vWc/0dfxJEdIiLKMTj/j74GR3aIiCjH4Pw/+hoc2SEiIiJF40wuIiIiUjSGHSIiIlI0hh0iIiJSNIYdIiIiUjSGHSIiIlI0hh0iIiJSNIYdItKp7t27Q6VSpXrcv38/y8cOCAiAtbV11pskIkXhooJEpHMNGzbE6tWrtbbZ2NjoqZu0JSYmwtDQUN9tEJEEOLJDRDpnZGQEOzs7rYeBgQH++usvlClTBsbGxnB1dcWUKVPw/v17zdfNmzcPnp6eMDMzg4ODAwYMGICYmBgAwOHDh9GjRw9ERUVpRosmT54MAFCpVNi+fbtWD9bW1ggICAAAPHz4ECqVChs3bkTNmjVhbGyMdevWAQBWrFiBEiVKwNjYGMWLF8fixYs1x3j37h0GDRqEggULwtjYGE5OTpg1a5Z8Pzgi+ioc2SGibOHYsWPo2rUr/Pz8UL16dTx48AB9+vQBAPz8888APtwXyc/PDy4uLggJCcGAAQMwZswYLF68GFWqVMGCBQvg6+uLO3fuAADMzc0z1cO4ceMwd+5clC5dWhN4fH19sXDhQpQuXRqXLl1C7969YWZmhm7dusHPzw9///03Nm3aBEdHR4SFhSEsLEzaHwwRZRnDDhHp3D///KMVRBo1aoTXr19j3Lhx6NatGwDA1dUV06ZNw5gxYzRhZ9iwYZqvcXZ2xvTp09GvXz8sXrwYuXPnhpWVFVQqFezs7L6qr2HDhqF169aaz3/++WfMnTtXs83FxQU3b97E0qVL0a1bNzx+/Bhubm6oVq0aVCoVnJycvqouEcmLYYeIdK527dpYsmSJ5nMzMzN4eXnhxIkTmDFjhmZ7UlIS4uPjERcXB1NTU+zfvx+zZs3C7du3ER0djffv32vtz6py5cppPo6NjcWDBw/Qq1cv9O7dW7P9/fv3sLKyAvBhsnX9+vVRrFgxNGzYEE2bNkWDBg2y3AcRSYthh4h0zszMDEWKFNHaFhMTgylTpmiNrKQwNjbGw4cP0bRpU/Tv3x8zZsxA3rx5cfz4cfTq1Qvv3r37bNhRqVT49J7HiYmJafb1cT8AsHz5clSsWFHreQYGBgCAMmXKIDQ0FLt378b+/fvRvn171KtXD1u2bPnCT4CIdIlhh4iyhTJlyuDOnTupQlCKCxcuIDk5GXPnzoVa/eHaik2bNmk9J3fu3EhKSkr1tTY2Nnj27Jnm83v37iEuLu6z/dja2sLe3h4hISHo3Llzus+ztLTE999/j++//x5t27ZFw4YN8erVK+TNm/ezxyci3WHYIaJswdfXF02bNoWjoyPatm0LtVqNK1eu4Pr165g+fTqKFCmCxMRE/P7772jWrBlOnDgBf39/rWM4OzsjJiYGBw4cgLe3N0xNTWFqaoo6depg4cKFqFy5MpKSkjB27NgMXVY+ZcoUDBkyBFZWVmjYsCESEhJw/vx5vH79GiNGjMC8efNQsGBBlC5dGmq1Gps3b4adnR3X+iHKZnjpORFlCz4+Pvjnn3+wd+9elC9fHpUqVcL8+fM1k369vb0xb948/PLLLyhZsiTWrVuX6jLvKlWqoF+/fvj+++9hY2ODOXPmAADmzp0LBwcHVK9eHZ06dcKoUaMyNMfnxx9/xIoVK7B69Wp4enqiZs2aCAgIgIuLCwDAwsICc+bMQbly5VC+fHk8fPgQu3bt0ow8EVH2oBKfnsgmIiIiUhC+/SAiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRft/cuJVryJMi3sAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "percent_missing=(df.isnull().sum()*100/df.shape[0]).sort_values(ascending=True)\n",
        "plt.title(\"Missing Value Analysis\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"% of missing values\")\n",
        "plt.bar(percent_missing.sort_values(ascending=False).index,percent_missing.sort_values(ascending=False),color=(0.1, 0.1, 0.1, 0.1),edgecolor='blue')\n",
        "plt.xticks(rotation=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:53:59.651672Z",
          "iopub.status.busy": "2024-10-29T20:53:59.650921Z",
          "iopub.status.idle": "2024-10-29T20:53:59.857931Z",
          "shell.execute_reply": "2024-10-29T20:53:59.856086Z",
          "shell.execute_reply.started": "2024-10-29T20:53:59.651630Z"
        },
        "id": "2kKQbH7_bTN5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"card_id\"] = df[\"User\"].astype(str) + \"_\" + df[\"Card\"].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:54:05.702054Z",
          "iopub.status.busy": "2024-10-29T20:54:05.700501Z",
          "iopub.status.idle": "2024-10-29T20:54:05.716073Z",
          "shell.execute_reply": "2024-10-29T20:54:05.713692Z",
          "shell.execute_reply.started": "2024-10-29T20:54:05.701955Z"
        },
        "id": "PO20hI3nbTN5",
        "outputId": "9edd45d1-29f2-4407-aa47-45ccbbd5aab3",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     $95.00\n",
              "1    $100.00\n",
              "2     $80.00\n",
              "3      $2.85\n",
              "4      $8.20\n",
              "Name: Amount, dtype: object"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Amount.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:54:21.030808Z",
          "iopub.status.busy": "2024-10-29T20:54:21.030319Z",
          "iopub.status.idle": "2024-10-29T20:54:21.439499Z",
          "shell.execute_reply": "2024-10-29T20:54:21.438060Z",
          "shell.execute_reply.started": "2024-10-29T20:54:21.030768Z"
        },
        "id": "SxBLy6lbbTN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "df[\"Amount\"]=df[\"Amount\"].str.replace(\"$\",\"\").astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:54:41.001710Z",
          "iopub.status.busy": "2024-10-29T20:54:41.000289Z",
          "iopub.status.idle": "2024-10-29T20:54:41.158880Z",
          "shell.execute_reply": "2024-10-29T20:54:41.157551Z",
          "shell.execute_reply.started": "2024-10-29T20:54:41.001654Z"
        },
        "id": "GZWvcgIDbTN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "df[\"Hour\"] = df[\"Time\"].str [0:2]\n",
        "df[\"Minute\"] = df[\"Time\"].str [3:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:54:47.160431Z",
          "iopub.status.busy": "2024-10-29T20:54:47.159934Z",
          "iopub.status.idle": "2024-10-29T20:54:47.171564Z",
          "shell.execute_reply": "2024-10-29T20:54:47.170063Z",
          "shell.execute_reply.started": "2024-10-29T20:54:47.160388Z"
        },
        "id": "bPskQ5ONbTN6",
        "outputId": "ae5da434-efb2-45a2-eb1a-57cbd9414509",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        13\n",
              "1        11\n",
              "2        07\n",
              "3        05\n",
              "4        07\n",
              "         ..\n",
              "99995    18\n",
              "99996    11\n",
              "99997    06\n",
              "99998    01\n",
              "99999    11\n",
              "Name: Hour, Length: 100000, dtype: object"
            ]
          },
          "execution_count": 453,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:54:51.667857Z",
          "iopub.status.busy": "2024-10-29T20:54:51.667339Z",
          "iopub.status.idle": "2024-10-29T20:54:51.678162Z",
          "shell.execute_reply": "2024-10-29T20:54:51.676759Z",
          "shell.execute_reply.started": "2024-10-29T20:54:51.667816Z"
        },
        "id": "5a20i_dzbTN6",
        "outputId": "06bc1b5c-f5ee-437b-a39a-a249d6e72803",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        15\n",
              "1        19\n",
              "2        11\n",
              "3        35\n",
              "4        46\n",
              "         ..\n",
              "99995    38\n",
              "99996    51\n",
              "99997    13\n",
              "99998    01\n",
              "99999    00\n",
              "Name: Minute, Length: 100000, dtype: object"
            ]
          },
          "execution_count": 454,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.Minute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:54:56.935359Z",
          "iopub.status.busy": "2024-10-29T20:54:56.934898Z",
          "iopub.status.idle": "2024-10-29T20:54:57.251047Z",
          "shell.execute_reply": "2024-10-29T20:54:57.249867Z",
          "shell.execute_reply.started": "2024-10-29T20:54:56.935320Z"
        },
        "id": "rYm-_GVWbTN6",
        "outputId": "773f4a1a-763c-4413-e53e-9cd350b41472",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   Year            100000 non-null  int64  \n",
            " 1   Month           100000 non-null  int64  \n",
            " 2   Day             100000 non-null  int64  \n",
            " 3   Amount          100000 non-null  float64\n",
            " 4   Use Chip        100000 non-null  object \n",
            " 5   Merchant Name   100000 non-null  int64  \n",
            " 6   Merchant City   100000 non-null  object \n",
            " 7   Merchant State  83768 non-null   object \n",
            " 8   Zip             81099 non-null   float64\n",
            " 9   MCC             100000 non-null  int64  \n",
            " 10  Errors?         1847 non-null    object \n",
            " 11  Is Fraud?       100000 non-null  object \n",
            " 12  card_id         100000 non-null  object \n",
            " 13  Hour            100000 non-null  object \n",
            " 14  Minute          100000 non-null  object \n",
            "dtypes: float64(2), int64(5), object(8)\n",
            "memory usage: 11.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df = df.drop([\"Time\",\"User\",\"Card\"],axis=1)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:55:01.690415Z",
          "iopub.status.busy": "2024-10-29T20:55:01.689957Z",
          "iopub.status.idle": "2024-10-29T20:55:01.705674Z",
          "shell.execute_reply": "2024-10-29T20:55:01.704060Z",
          "shell.execute_reply.started": "2024-10-29T20:55:01.690377Z"
        },
        "id": "cEw2PE-0bTN6",
        "outputId": "7fd1efe9-b320-4d4d-a56e-0ab27e5c00d5",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([nan, 'Insufficient Balance', 'Bad PIN', 'Technical Glitch',\n",
              "       'Bad CVV', 'Bad Card Number', 'Bad Expiration',\n",
              "       'Bad Card Number,Insufficient Balance',\n",
              "       'Bad PIN,Insufficient Balance',\n",
              "       'Insufficient Balance,Technical Glitch', 'Bad Zipcode',\n",
              "       'Bad CVV,Insufficient Balance'], dtype=object)"
            ]
          },
          "execution_count": 456,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Errors?\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:55:16.402854Z",
          "iopub.status.busy": "2024-10-29T20:55:16.402422Z",
          "iopub.status.idle": "2024-10-29T20:55:16.418952Z",
          "shell.execute_reply": "2024-10-29T20:55:16.417466Z",
          "shell.execute_reply.started": "2024-10-29T20:55:16.402817Z"
        },
        "id": "QCvz9RygbTN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"Errors?\"]= df[\"Errors?\"].fillna(\"No error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:55:27.610576Z",
          "iopub.status.busy": "2024-10-29T20:55:27.610137Z",
          "iopub.status.idle": "2024-10-29T20:55:27.642500Z",
          "shell.execute_reply": "2024-10-29T20:55:27.641324Z",
          "shell.execute_reply.started": "2024-10-29T20:55:27.610530Z"
        },
        "id": "GYFzrjrAbTN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=[\"Merchant State\",\"Zip\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:55:38.442818Z",
          "iopub.status.busy": "2024-10-29T20:55:38.442368Z",
          "iopub.status.idle": "2024-10-29T20:55:38.491108Z",
          "shell.execute_reply": "2024-10-29T20:55:38.489838Z",
          "shell.execute_reply.started": "2024-10-29T20:55:38.442778Z"
        },
        "id": "CjrBOLnsbTN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "df[\"Is Fraud?\"] = df[\"Is Fraud?\"].apply(lambda x: 1 if x == 'Yes' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-29T20:55:45.091880Z",
          "iopub.status.busy": "2024-10-29T20:55:45.090867Z",
          "iopub.status.idle": "2024-10-29T20:55:45.232903Z",
          "shell.execute_reply": "2024-10-29T20:55:45.231865Z",
          "shell.execute_reply.started": "2024-10-29T20:55:45.091824Z"
        },
        "id": "E4ZiGIQJbTN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"Merchant City\"]=LabelEncoder().fit_transform(df[\"Merchant City\"])\n",
        "df[\"Use Chip\"]=LabelEncoder().fit_transform(df[\"Use Chip\"])\n",
        "df[\"Errors?\"]=LabelEncoder().fit_transform(df[\"Errors?\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-29T20:55:48.559346Z",
          "iopub.status.busy": "2024-10-29T20:55:48.558599Z",
          "iopub.status.idle": "2024-10-29T20:55:48.569478Z",
          "shell.execute_reply": "2024-10-29T20:55:48.567858Z",
          "shell.execute_reply.started": "2024-10-29T20:55:48.559279Z"
        },
        "id": "oLk1DCQGbTN6",
        "outputId": "18f63e29-bfcf-4544-f861-c3778a2296e7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10,  8,  5, 11,  0,  2,  4,  3,  6,  9,  7,  1])"
            ]
          },
          "execution_count": 461,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"Errors?\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDUDQjqRvI0T"
      },
      "source": [
        "-----------GNN---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCikPjHYsG5B"
      },
      "outputs": [],
      "source": [
        "# Create an empty graph\n",
        "G = nx.MultiGraph()\n",
        "\n",
        "# Add nodes to the graph for each unique card_id, merchant_name\n",
        "G.add_nodes_from(df[\"card_id\"].unique(), type='card_id')\n",
        "G.add_nodes_from(df[\"Merchant Name\"].unique(), type='merchant_name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bu4qJFxsIeA"
      },
      "outputs": [],
      "source": [
        "# Add edges and properties to the edges\n",
        "for _, row in df.iterrows():\n",
        "    # Create a variable for each properties for each edge\n",
        "\n",
        "        year = row[\"Year\"],\n",
        "        month = row[\"Month\"],\n",
        "        day = row[\"Day\"],\n",
        "        hour = row[\"Hour\"],\n",
        "        minute =row[\"Minute\"],\n",
        "        amount = row[\"Amount\"],\n",
        "        use_chip =  row[\"Use Chip\"],\n",
        "        merchant_city = row[\"Merchant City\"],\n",
        "        errors =  row[\"Errors?\"],\n",
        "        mcc = row['MCC']\n",
        "\n",
        "\n",
        "        G.add_edge(row['card_id'], row['Merchant Name'], year = year , month = month , day = day ,\n",
        "              hour = hour , minute = minute , amount = amount , use_chip = use_chip ,\n",
        "              merchant_city = merchant_city , errors = errors , mcc = mcc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dnnLXyasONk",
        "outputId": "5af67146-3e53-4cfd-933c-9fab7a813bdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of nodes: 16521\n",
            "Number of edges: 100000\n"
          ]
        }
      ],
      "source": [
        "# Get the number of nodes and edges in the graph\n",
        "num_nodes = G.number_of_nodes()\n",
        "num_edges = G.number_of_edges()\n",
        "\n",
        "# Print the number of nodes and edges\n",
        "print(\"Number of nodes:\", num_nodes)\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9I6lJxN-xnC"
      },
      "outputs": [],
      "source": [
        "# Convert the graph to an adjacency matrix\n",
        "adj_matrix = nx.adjacency_matrix(G).todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ6OntVC-zZy",
        "outputId": "3722f0d6-7a9b-4f82-9148-4ed2291c16b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16521, 16521)"
            ]
          },
          "execution_count": 466,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adj_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKNFmvbH-1l5",
        "outputId": "af6bf7e1-7ee6-46ae-d732-42651ea107c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node: 697_1, Properties: card_id\n",
            "Node: 226_2, Properties: card_id\n",
            "Node: 1662_1, Properties: card_id\n",
            "Node: 1997_0, Properties: card_id\n",
            "Node: 1255_0, Properties: card_id\n",
            "Node: 396_1, Properties: card_id\n",
            "Node: 393_1, Properties: card_id\n",
            "Node: 790_1, Properties: card_id\n",
            "Node: 271_2, Properties: card_id\n",
            "Node: 1889_1, Properties: card_id\n"
          ]
        }
      ],
      "source": [
        "# Get a small sample of the nodes in the graph\n",
        "sample_nodes = list(G.nodes())[:10]\n",
        "\n",
        "# Retrieve the properties of the sample nodes\n",
        "node_properties = nx.get_node_attributes(G, 'type')\n",
        "\n",
        "# Print the properties of the sample nodes\n",
        "for node in sample_nodes:\n",
        "    print(f\"Node: {node}, Properties: {node_properties[node]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_cfJbKM-5-f",
        "outputId": "7f7b98e3-5ff0-4ec0-949b-0cde6f762d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: {'year': (2015,), 'month': (1,), 'day': (9,), 'hour': ('13',), 'minute': ('15',), 'amount': (95.0,), 'use_chip': (0,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5541}, 1: {'year': (2018,), 'month': (1,), 'day': (12,), 'hour': ('16',), 'minute': ('57',), 'amount': (103.24,), 'use_chip': (0,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5541}}\n",
            "{0: {'year': (2015,), 'month': (1,), 'day': (9,), 'hour': ('13',), 'minute': ('15',), 'amount': (95.0,), 'use_chip': (0,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5541}, 1: {'year': (2018,), 'month': (1,), 'day': (12,), 'hour': ('16',), 'minute': ('57',), 'amount': (103.24,), 'use_chip': (0,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5541}}\n",
            "{0: {'year': (2014,), 'month': (12,), 'day': (20,), 'hour': ('11',), 'minute': ('32',), 'amount': (21.72,), 'use_chip': (2,), 'merchant_city': (2817,), 'errors': (10,), 'mcc': 5311}}\n",
            "{0: {'year': (2006,), 'month': (9,), 'day': (19,), 'hour': ('07',), 'minute': ('21',), 'amount': (3.65,), 'use_chip': (2,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}, 1: {'year': (2006,), 'month': (9,), 'day': (6,), 'hour': ('16',), 'minute': ('32',), 'amount': (102.07,), 'use_chip': (2,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}, 2: {'year': (2019,), 'month': (6,), 'day': (8,), 'hour': ('16',), 'minute': ('40',), 'amount': (84.47,), 'use_chip': (0,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}, 3: {'year': (2011,), 'month': (11,), 'day': (4,), 'hour': ('07',), 'minute': ('08',), 'amount': (3.9,), 'use_chip': (2,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}}\n",
            "{0: {'year': (2006,), 'month': (9,), 'day': (19,), 'hour': ('07',), 'minute': ('21',), 'amount': (3.65,), 'use_chip': (2,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}, 1: {'year': (2006,), 'month': (9,), 'day': (6,), 'hour': ('16',), 'minute': ('32',), 'amount': (102.07,), 'use_chip': (2,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}, 2: {'year': (2019,), 'month': (6,), 'day': (8,), 'hour': ('16',), 'minute': ('40',), 'amount': (84.47,), 'use_chip': (0,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}, 3: {'year': (2011,), 'month': (11,), 'day': (4,), 'hour': ('07',), 'minute': ('08',), 'amount': (3.9,), 'use_chip': (2,), 'merchant_city': (2632,), 'errors': (10,), 'mcc': 5411}}\n"
          ]
        }
      ],
      "source": [
        "sample_size = 5\n",
        "for i, edge in enumerate(G.edges()):\n",
        "    print(G.get_edge_data(*edge))\n",
        "    if i >= sample_size - 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJgDyj_s-_bY",
        "outputId": "23e7c957-57b5-4823-eba0-c02d15c38a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Property value: (10,), Count: 98153\n",
            "Property value: (8,), Count: 1042\n",
            "Property value: (4,), Count: 82\n",
            "Property value: (0,), Count: 126\n",
            "Property value: (11,), Count: 213\n",
            "Property value: (5,), Count: 282\n",
            "Property value: (2,), Count: 88\n",
            "Property value: (6,), Count: 3\n",
            "Property value: (7,), Count: 5\n",
            "Property value: (9,), Count: 3\n",
            "Property value: (1,), Count: 2\n",
            "Property value: (3,), Count: 1\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the properties errors of all the edges\n",
        "edge_properties = nx.get_edge_attributes(G, 'errors')\n",
        "\n",
        "# Count the number of edges by property value\n",
        "edge_count_by_property = Counter(edge_properties.values())\n",
        "\n",
        "# Print the count of edges by property value\n",
        "for property_value, count in edge_count_by_property.items():\n",
        "    print(f\"Property value: {property_value}, Count: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mOJnKVb_SuZ"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for input into the model\n",
        "edge_list = list(G.edges(data=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsgDwr2__T3h",
        "outputId": "f75a1d40-1d29-492a-935d-859652642a1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(2006,), (9,), (6,), ('16',), ('32',), (102.07,), (2,), (2632,), (10,), 5411]"
            ]
          },
          "execution_count": 471,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(edge_list[i][2].values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOwIHnhN_gaY"
      },
      "outputs": [],
      "source": [
        "class FraudGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(FraudGNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x.squeeze(-1)\n",
        "\n",
        "# Prepare the data for input into the model\n",
        "edge_list = list(G.edges(data=True))\n",
        "x = []\n",
        "for edge in edge_list:\n",
        "    edge_values = list(edge[2].values())\n",
        "    edge_values = [float(i[0]) if type(i) == tuple and type(i[0]) == str else i[0] if type(i) == tuple else i for i in edge_values]\n",
        "    x.append(edge_values)\n",
        "x = torch.tensor(x, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiKJ9hs7AJKS"
      },
      "outputs": [],
      "source": [
        "target = torch.tensor(df['Is Fraud?'].values, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynCvQOJ8ALuA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid =  train_test_split(x, target, test_size=0.2, stratify=target)\n",
        "x_valid, x_test, y_valid, y_test =  train_test_split(x_valid, y_valid, test_size=0.5, stratify=y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK7S8JYEAPpX"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "input_dim = len(x[0])\n",
        "hidden_dim = 16\n",
        "model = FraudGNN(input_dim, hidden_dim)\n",
        "num_epochs=1000\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "pos_weight = torch.tensor([len(df[df['Is Fraud?'] == 0]) / len(df[df['Is Fraud?'] == 1]) ])\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6M3a_evEuWL",
        "outputId": "19298633-2811-4f2a-ad63-b0d51934c9b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 314.7911682128906\n",
            "Epoch: 20, Loss: 35.44382858276367\n",
            "Epoch: 40, Loss: 11.359902381896973\n",
            "Epoch: 60, Loss: 4.441132068634033\n",
            "Epoch: 80, Loss: 1.914249062538147\n",
            "Epoch: 100, Loss: 2.5003931522369385\n",
            "Epoch: 120, Loss: 7.682397365570068\n",
            "Epoch: 140, Loss: 5.1276397705078125\n",
            "Epoch: 160, Loss: 2.541593551635742\n",
            "Epoch: 180, Loss: 6.111086368560791\n",
            "Epoch: 200, Loss: 3.9240593910217285\n",
            "Epoch: 220, Loss: 2.3220157623291016\n",
            "Epoch: 240, Loss: 5.169547080993652\n",
            "Epoch: 260, Loss: 3.5848677158355713\n",
            "Epoch: 280, Loss: 1.9791350364685059\n",
            "Epoch: 300, Loss: 4.233722686767578\n",
            "Epoch: 320, Loss: 3.284396171569824\n",
            "Epoch: 340, Loss: 1.3745535612106323\n",
            "Epoch: 360, Loss: 1.2889937162399292\n",
            "Epoch: 380, Loss: 1.2715200185775757\n",
            "Epoch: 400, Loss: 1.2619109153747559\n",
            "Epoch: 420, Loss: 1.2591643333435059\n",
            "Epoch: 440, Loss: 1.2574940919876099\n",
            "Epoch: 460, Loss: 1.2562283277511597\n",
            "Epoch: 480, Loss: 1.255220890045166\n",
            "Epoch: 500, Loss: 1.2543889284133911\n",
            "Epoch: 520, Loss: 1.2536958456039429\n",
            "Epoch: 540, Loss: 1.2531229257583618\n",
            "Epoch: 560, Loss: 1.2526336908340454\n",
            "Epoch: 580, Loss: 1.252199411392212\n",
            "Epoch: 600, Loss: 1.2518055438995361\n",
            "Epoch: 620, Loss: 1.251448154449463\n",
            "Epoch: 640, Loss: 1.2511165142059326\n",
            "Epoch: 660, Loss: 1.250817060470581\n",
            "Epoch: 680, Loss: 1.250544548034668\n",
            "Epoch: 700, Loss: 1.2502963542938232\n",
            "Epoch: 720, Loss: 1.2709635496139526\n",
            "Epoch: 740, Loss: 1.3448481559753418\n",
            "Epoch: 760, Loss: 1.2995221614837646\n",
            "Epoch: 780, Loss: 1.3165208101272583\n",
            "Epoch: 800, Loss: 1.3156012296676636\n",
            "Epoch: 820, Loss: 1.3221814632415771\n",
            "Epoch: 840, Loss: 1.3256936073303223\n",
            "Epoch: 860, Loss: 1.3313076496124268\n",
            "Epoch: 880, Loss: 1.3369677066802979\n",
            "Epoch: 900, Loss: 1.3421273231506348\n",
            "Epoch: 920, Loss: 1.3473565578460693\n",
            "Epoch: 940, Loss: 1.3510106801986694\n",
            "Epoch: 960, Loss: 1.3526719808578491\n",
            "Epoch: 980, Loss: 1.3546843528747559\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "for i in range(num_epochs):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    # Compute the loss\n",
        "    loss = criterion(output, target)\n",
        "    if i % 20 == 0:\n",
        "        print(f'Epoch: {i}, Loss: {loss.item()}')\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "    # Update the parameters\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwRHWidNA4sG",
        "outputId": "4f9e5910-7043-4022-cb75-0f8e75435f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.7687000036239624\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():  # Disable gradient computation for inference\n",
        "    test_output = model(x_test)\n",
        "    test_predictions = torch.sigmoid(test_output)\n",
        "    predicted_labels = (test_predictions > 0.7).float()\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "test_accuracy = torch.mean((predicted_labels == y_test).float())\n",
        "print(f'Test Accuracy: {test_accuracy.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM4lF7_ZEJn0",
        "outputId": "1407864c-c3b3-4eb1-d840-da191b507610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Correct fraud predictions: 179/1000\n"
          ]
        }
      ],
      "source": [
        "# Filter for fraud cases in the test set\n",
        "fraud_indices = (y_test == 1).nonzero(as_tuple=True)[0]\n",
        "fraud_predictions = predicted_labels[fraud_indices]\n",
        "fraud_actual = y_test[fraud_indices]\n",
        "\n",
        "# Print the actual and predicted values for fraud cases\n",
        "for i in range(len(fraud_actual)):\n",
        "    print(f\"Actual: {fraud_actual[i].item()}, Predicted: {fraud_predictions[i].item()}\")\n",
        "\n",
        "# Calculate how many fraud cases were predicted correctly\n",
        "correct_fraud_predictions = (fraud_predictions == fraud_actual).sum().item()\n",
        "total_fraud_cases = len(fraud_actual)\n",
        "\n",
        "print(f\"Correct fraud predictions: {correct_fraud_predictions}/{total_fraud_cases}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNiKLWKNCD_O",
        "outputId": "9127c836-be0d-43d0-e20e-6b6011fb37ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.1071\n",
            "Recall: 0.1790\n",
            "F1 Score: 0.1340\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert tensors to numpy arrays for Scikit-Learn compatibility\n",
        "y_test_np = y_test.cpu().numpy()  # Convert test labels to numpy array\n",
        "predicted_labels_np = predicted_labels.cpu().numpy()  # Convert predictions to numpy array\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_test_np, predicted_labels_np)\n",
        "recall = recall_score(y_test_np, predicted_labels_np)\n",
        "f1 = f1_score(y_test_np, predicted_labels_np)\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uabbS6w6CC1f"
      },
      "source": [
        "--------GAT------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31kq7PThCb0N",
        "outputId": "0d2b5c84-bfc7-4634-a288-3ebd0e3e281a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-geometric in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch-geometric) (5.9.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYG8qPgxClpG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from torch_geometric.utils import from_networkx\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiJi0Qa3CwLl"
      },
      "outputs": [],
      "source": [
        "data = from_networkx(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBw3UD-eGfqF"
      },
      "outputs": [],
      "source": [
        "df['Hour'] = pd.to_numeric(df['Hour'], errors='coerce')\n",
        "df['Minute'] = pd.to_numeric(df['Minute'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxL0Ss7wI6Wk"
      },
      "outputs": [],
      "source": [
        "# Assuming 'card_id' and 'Merchant Name' are strings, we need to encode them\n",
        "card_to_idx = {card: idx for idx, card in enumerate(df['card_id'].unique())}\n",
        "merchant_to_idx = {merchant: idx for idx, merchant in enumerate(df['Merchant Name'].unique())}\n",
        "\n",
        "# Convert 'card_id' and 'Merchant Name' to numerical IDs\n",
        "df['card_id_idx'] = df['card_id'].map(card_to_idx)\n",
        "df['merchant_id_idx'] = df['Merchant Name'].map(merchant_to_idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPmqBVFOI7d6",
        "outputId": "56b2cc67-8942-4279-9955-1b43369ff195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 15 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   Year             100000 non-null  int64  \n",
            " 1   Month            100000 non-null  int64  \n",
            " 2   Day              100000 non-null  int64  \n",
            " 3   Amount           100000 non-null  float64\n",
            " 4   Use Chip         100000 non-null  int32  \n",
            " 5   Merchant Name    100000 non-null  int64  \n",
            " 6   Merchant City    100000 non-null  int32  \n",
            " 7   MCC              100000 non-null  int64  \n",
            " 8   Errors?          100000 non-null  int32  \n",
            " 9   Is Fraud?        100000 non-null  int64  \n",
            " 10  card_id          100000 non-null  object \n",
            " 11  Hour             100000 non-null  int64  \n",
            " 12  Minute           100000 non-null  int64  \n",
            " 13  card_id_idx      100000 non-null  int64  \n",
            " 14  merchant_id_idx  100000 non-null  int64  \n",
            "dtypes: float64(1), int32(3), int64(10), object(1)\n",
            "memory usage: 10.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-dsVVXmC6d_",
        "outputId": "7c8e7251-c310-44bb-ba0c-403748158d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2015, 1, 9, 13, 15, 95.0, 0, 2632, 10, 5541], [2019, 12, 4, 11, 19, 100.0, 0, 5008, 10, 4829], [2012, 11, 22, 7, 11, 80.0, 2, 5123, 10, 5541], [2017, 6, 23, 5, 35, 2.85, 0, 1368, 10, 5411], [2019, 8, 29, 7, 46, 8.2, 0, 4407, 10, 5812]]\n"
          ]
        }
      ],
      "source": [
        "edge_features = []\n",
        "edges = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    edge_feature = [\n",
        "        row[\"Year\"], row[\"Month\"], row[\"Day\"], row[\"Hour\"], row[\"Minute\"],\n",
        "        row[\"Amount\"], row[\"Use Chip\"], row[\"Merchant City\"], row[\"Errors?\"], row[\"MCC\"]\n",
        "    ]\n",
        "    edge_features.append(edge_feature)  # Ensure each item is a list of values\n",
        "    edges.append((row['card_id_idx'], row['merchant_id_idx']))\n",
        "# Debug: Print a sample of edge_features to confirm structure\n",
        "print(edge_features[:5])  # This should now show a list of lists with integers and floats\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSxVrQSYEx6F"
      },
      "outputs": [],
      "source": [
        "# Convert edge features to a tensor\n",
        "edge_attr_tensor = torch.tensor(edge_features, dtype=torch.float)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7tGAO9wvI0e"
      },
      "outputs": [],
      "source": [
        "edge_attr_tensor[:, 8] = edge_attr_tensor[:, 8] * 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8o1vcZKFJql"
      },
      "outputs": [],
      "source": [
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2oKV1y9vI0e",
        "outputId": "1e0bbc66-d032-4d3e-8ca6-9d45eb18e64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 100000], edge_attr=[100000, 10])\n"
          ]
        }
      ],
      "source": [
        "data = Data(edge_index=edge_index, edge_attr=edge_attr_tensor)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzcFS4muvI0e",
        "outputId": "d3f2c558-3c83-42b3-ae2b-229a72fa3a4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\radhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch_geometric\\data\\storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'edge_index', 'edge_attr'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "num_nodes = data.num_nodes  # Replace with your graph's number of nodes\n",
        "node_features = torch.ones((num_nodes, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1dMcWQYnU7C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, BatchNorm\n",
        "\n",
        "class EdgeGAT(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
        "        super(EdgeGAT, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # First GATConv layer\n",
        "        self.conv1 = GATConv(in_channels, out_channels, heads=2, concat=True, dropout=0.1, edge_dim=in_channels)\n",
        "        self.bn1 = BatchNorm(out_channels * 2)  # Adjusted for concatenation\n",
        "\n",
        "        # Intermediate GATConv layer\n",
        "        self.conv3 = GATConv(out_channels * 2, out_channels, heads=2, concat=True, dropout=0.1, edge_dim=in_channels)\n",
        "        self.bn2 = BatchNorm(out_channels * 2)\n",
        "\n",
        "        # Final GATConv layer for edge-level classification\n",
        "        self.conv2 = GATConv(out_channels * 2, 1, heads=1, concat=False, dropout=0.1, edge_dim=in_channels)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # Apply the first GATConv layer\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn1(x)  # Apply BatchNorm\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Apply the intermediate GATConv layer\n",
        "        x = self.conv3(x, edge_index, edge_attr)\n",
        "        x = F.relu(x)\n",
        "        x = self.bn2(x)  # Apply BatchNorm\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Apply the final GATConv layer for classification\n",
        "        x = self.conv2(x, edge_index, edge_attr)\n",
        "\n",
        "        # Aggregate node features for each edge (source + target nodes)\n",
        "        source, target = edge_index  # Split edge_index into source and target nodes\n",
        "        edge_features = (x[source] + x[target]) / 2  # Example: mean of source and target features\n",
        "\n",
        "        return edge_features.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCq-_ybPnU7C",
        "outputId": "decaa54d-7314-4efd-ce1a-b0b8e0a346e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output size: torch.Size([80000])\n"
          ]
        }
      ],
      "source": [
        "# Example data\n",
        "num_nodes = 11521\n",
        "num_edges = 80000\n",
        "in_channels = 10  # Feature dimension\n",
        "out_channels = 32  # Hidden dimension\n",
        "\n",
        "node_features = torch.rand((num_nodes, in_channels))\n",
        "edge_index = torch.randint(0, num_nodes, (2, num_edges))  # Random edge index\n",
        "edge_attr = torch.rand((num_edges, in_channels))  # Edge attributes\n",
        "\n",
        "# Labels for edge-level classification\n",
        "train_y = torch.tensor(df['Is Fraud?'].values).float()\n",
        "\n",
        "# Initialize model\n",
        "model = EdgeGAT(in_channels=in_channels, out_channels=out_channels)\n",
        "\n",
        "# Forward pass\n",
        "out = model(node_features, edge_index, edge_attr)\n",
        "\n",
        "print(f\"Output size: {out.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDkjepRJvI0f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the loss function and optimizer\n",
        "pos_weight = torch.tensor([len(df[df['Is Fraud?'] == 0]) / len(df[df['Is Fraud?'] == 1]) ])\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxwM8QGnvI0f",
        "outputId": "f9657898-993a-4157-fec7-ab60393a7aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node Features size: torch.Size([11521, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split data (ensure correct data handling)\n",
        "train_edge_index, test_edge_index, train_edge_attr, test_edge_attr = train_test_split(\n",
        "    data.edge_index.t().numpy(), data.edge_attr.numpy(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert to tensors\n",
        "train_edge_index = torch.tensor(train_edge_index.T, dtype=torch.long)\n",
        "test_edge_index = torch.tensor(test_edge_index.T, dtype=torch.long)\n",
        "train_edge_attr = torch.tensor(train_edge_attr, dtype=torch.float)\n",
        "test_edge_attr = torch.tensor(test_edge_attr, dtype=torch.float)\n",
        "\n",
        "print(f\"Node Features size: {node_features.size()}\")  # Should be [num_nodes, feature_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zYbK8I2vI0f",
        "outputId": "4dbf0527-7332-4794-d329-d4afcd3d02b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Y size: torch.Size([80000]), Test Y size: torch.Size([20000])\n",
            "Train Edge Index size: torch.Size([2, 80000])\n",
            "Output size: torch.Size([80000]), Target size: torch.Size([80000])\n"
          ]
        }
      ],
      "source": [
        "# Map 'y' to edge-level targets based on the DataFrame\n",
        "train_indices = train_edge_index.t().numpy()\n",
        "test_indices = test_edge_index.t().numpy()\n",
        "\n",
        "# Create train_y and test_y by mapping edges to corresponding 'Is Fraud?' values\n",
        "train_y = []\n",
        "for edge in train_indices:\n",
        "    src, tgt = edge\n",
        "    label = df[(df['card_id_idx'] == src) & (df['merchant_id_idx'] == tgt)]['Is Fraud?'].values\n",
        "    train_y.append(label[0] if len(label) > 0 else 0)  # Default to 0 if no match\n",
        "\n",
        "test_y = []\n",
        "for edge in test_indices:\n",
        "    src, tgt = edge\n",
        "    label = df[(df['card_id_idx'] == src) & (df['merchant_id_idx'] == tgt)]['Is Fraud?'].values\n",
        "    test_y.append(label[0] if len(label) > 0 else 0)  # Default to 0 if no match\n",
        "\n",
        "# Convert to tensors\n",
        "train_y = torch.tensor(train_y, dtype=torch.float)\n",
        "test_y = torch.tensor(test_y, dtype=torch.float)\n",
        "\n",
        "# Debugging: Check sizes\n",
        "print(f\"Train Y size: {train_y.size()}, Test Y size: {test_y.size()}\")\n",
        "\n",
        "# Check train_edge_index dimensions\n",
        "print(f\"Train Edge Index size: {train_edge_index.size()}\")  # Should be [2, num_edges]\n",
        "\n",
        "# Verify the number of edges matches train_y size\n",
        "assert train_edge_index.size(1) == train_y.size(0), \"Mismatch between train_edge_index and train_y sizes!\"\n",
        "assert test_edge_index.size(1) == test_y.size(0), \"Mismatch between test_edge_index and test_y sizes!\"\n",
        "\n",
        "print(f\"Output size: {out.squeeze().size()}, Target size: {train_y.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-zbxPdpal-w",
        "outputId": "241a2428-c9e7-4f68-fa7e-1220079054d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.4837028980255127\n",
            "Epoch 50, Loss: 1.15700101852417\n",
            "Epoch 100, Loss: 1.1367149353027344\n",
            "Epoch 150, Loss: 1.133524775505066\n",
            "Epoch 200, Loss: 1.0798358917236328\n",
            "Epoch 250, Loss: 1.0709763765335083\n",
            "Epoch 300, Loss: 1.0905072689056396\n",
            "Epoch 350, Loss: 1.0714013576507568\n",
            "Epoch 400, Loss: 1.0979256629943848\n",
            "Epoch 450, Loss: 1.0451369285583496\n",
            "Output size: torch.Size([80000]), Train Y size: torch.Size([80000])\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    out = model(node_features, train_edge_index, train_edge_attr).squeeze()  # Squeeze to match target dimensions\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = criterion(out, train_y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "# Debugging: Ensure output and target shapes align\n",
        "print(f\"Output size: {out.size()}, Train Y size: {train_y.size()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43PCiekJvI0f",
        "outputId": "66be360b-6ab0-462b-d388-26e0cfaa59d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Output size: torch.Size([20000]), Test Y size: torch.Size([20000])\n",
            "Precision: 0.0993\n",
            "Recall: 0.4637\n",
            "F1 Score: 0.1636\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 1.0\n",
            "Actual: 1.0, Predicted: 0.0\n",
            "Correct fraud predictions: 474/1000\n"
          ]
        }
      ],
      "source": [
        "# Evaluation phase\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out_test = model(node_features, test_edge_index, test_edge_attr).squeeze()\n",
        "\n",
        "    # Debugging test output\n",
        "    print(f\"Test Output size: {out_test.size()}, Test Y size: {test_y.size()}\")\n",
        "\n",
        "    # Ensure sizes match\n",
        "    assert out_test.size(0) == test_y.size(0), \"Mismatch between test output and test_y sizes!\"\n",
        "\n",
        "    # Binary classification threshold\n",
        "    threshold = 0.1\n",
        "    predicted_labels = (out_test > threshold).float()\n",
        "\n",
        "    # Evaluate metrics\n",
        "    precision = precision_score(test_y.numpy(), predicted_labels.numpy())\n",
        "    recall = recall_score(test_y.numpy(), predicted_labels.numpy())\n",
        "    f1 = f1_score(test_y.numpy(), predicted_labels.numpy())\n",
        "\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "    print(f'F1 Score: {f1:.4f}')\n",
        "\n",
        "# Filter for fraud cases in the test set\n",
        "fraud_indices = (y_test == 1).nonzero(as_tuple=True)[0]\n",
        "fraud_predictions = predicted_labels[fraud_indices]\n",
        "fraud_actual = y_test[fraud_indices]\n",
        "\n",
        "# Print the actual and predicted values for fraud cases\n",
        "for i in range(len(fraud_actual)):\n",
        "    print(f\"Actual: {fraud_actual[i].item()}, Predicted: {fraud_predictions[i].item()}\")\n",
        "\n",
        "# Calculate how many fraud cases were predicted correctly\n",
        "correct_fraud_predictions = (fraud_predictions == fraud_actual).sum().item()\n",
        "total_fraud_cases = len(fraud_actual)\n",
        "\n",
        "print(f\"Correct fraud predictions: {correct_fraud_predictions}/{total_fraud_cases}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAyj3nt-7GTn"
      },
      "source": [
        "----GraphSAGE---------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LOkDUVJnU7D",
        "outputId": "cc3bbb85-a644-4128-b617-d096bdeecf4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch_geometric) (5.9.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch_geometric) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\radhi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJyawf8I7JQh"
      },
      "outputs": [],
      "source": [
        "# Import necessary SMOTE module\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import from_networkx\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the networkx graph (G) to PyG Data format\n",
        "graph_data = from_networkx(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSLem3bR8JRR"
      },
      "outputs": [],
      "source": [
        "card_to_idx = {card: idx for idx, card in enumerate(df['card_id'].unique())}\n",
        "merchant_to_idx = {merchant: idx for idx, merchant in enumerate(df['Merchant Name'].unique())}\n",
        "\n",
        "df['card_id_idx'] = df['card_id'].map(card_to_idx)\n",
        "df['merchant_id_idx'] = df['Merchant Name'].map(merchant_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iESWDoi8OAx"
      },
      "outputs": [],
      "source": [
        "# Generate edge features and edges\n",
        "edge_features = []\n",
        "edges = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    edge_feature = [\n",
        "        row[\"Year\"], row[\"Month\"], row[\"Day\"], row[\"Hour\"], row[\"Minute\"],\n",
        "        row[\"Amount\"], row[\"Use Chip\"], row[\"Merchant City\"], row[\"Errors?\"], row[\"MCC\"]\n",
        "    ]\n",
        "    edge_features.append(edge_feature)\n",
        "    edges.append((row['card_id_idx'], row['merchant_id_idx']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6tKSGJe8RIT"
      },
      "outputs": [],
      "source": [
        "# Convert edge features to a tensor\n",
        "edge_attr_tensor = torch.tensor(edge_features, dtype=torch.float)\n",
        "\n",
        "# Convert edges to a tensor\n",
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bTe9BQh8TwR"
      },
      "outputs": [],
      "source": [
        "# Prepare node features\n",
        "num_nodes = len(df['card_id'].unique()) + len(df['Merchant Name'].unique())  # Number of unique nodes\n",
        "node_features = torch.ones((num_nodes, 10))  # Assuming 10 features for each node (can be adjusted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQjVl6Ox88YO"
      },
      "outputs": [],
      "source": [
        "# Define target labels (fraud detection) - Shape should correspond to number of edges\n",
        "target = torch.tensor(df['Is Fraud?'].values, dtype=torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHkha4LDnU7E",
        "outputId": "83fdb209-163b-4ac8-ebf9-65afd2a7d5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node features tensor shape: torch.Size([16521, 10])\n"
          ]
        }
      ],
      "source": [
        "print(\"Node features tensor shape:\", node_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHtU7EtE_In2",
        "outputId": "c6c13f31-1817-432a-fc47-2b46fcd33758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated node features: tensor([[0.8613, 0.6878, 0.1904,  ..., 0.7604, 0.3870, 0.5856],\n",
            "        [0.7433, 0.9734, 0.0075,  ..., 0.3014, 0.1968, 0.4411],\n",
            "        [0.2879, 0.6406, 0.6766,  ..., 0.3613, 0.0632, 0.8848],\n",
            "        ...,\n",
            "        [0.7644, 0.3546, 0.7272,  ..., 0.8397, 0.7537, 0.0994],\n",
            "        [0.8624, 0.8446, 0.9388,  ..., 0.9212, 0.4096, 0.5308],\n",
            "        [0.5941, 0.2412, 0.8736,  ..., 0.5506, 0.1766, 0.8093]])\n"
          ]
        }
      ],
      "source": [
        "card_ids = df['card_id'].unique()\n",
        "merchants = df['Merchant Name'].unique()\n",
        "\n",
        "# Create a mapping from card_id and Merchant Name to node index\n",
        "card_id_to_node = {card: idx for idx, card in enumerate(card_ids)}\n",
        "merchant_to_node = {merchant: idx + len(card_ids) for idx, merchant in enumerate(merchants)}\n",
        "\n",
        "# Assign random node features (or domain-specific features) for each unique node\n",
        "for card in card_ids:\n",
        "    idx = card_id_to_node[card]\n",
        "    node_features[idx] = torch.rand(10)  # Random features for the card (replace with actual features)\n",
        "\n",
        "for merchant in merchants:\n",
        "    idx = merchant_to_node[merchant]\n",
        "    node_features[idx] = torch.rand(10)  # Random features for the merchant (replace with actual features)\n",
        "\n",
        "print(\"Updated node features:\", node_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcBWo4gVnU7E"
      },
      "outputs": [],
      "source": [
        "# Create PyG Data object\n",
        "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr_tensor, y=target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4S4hphlBUKJ"
      },
      "outputs": [],
      "source": [
        "edge_index_train, edge_index_test, y_train, y_test = train_test_split(\n",
        "    data.edge_index.t().numpy(), data.y.numpy(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert back to PyTorch tensors\n",
        "edge_index_train = torch.tensor(edge_index_train.T, dtype=torch.long)\n",
        "edge_index_test = torch.tensor(edge_index_test.T, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float)\n",
        "\n",
        "# Split edge features into train and test\n",
        "edge_attr_train, edge_attr_test = train_test_split(\n",
        "    data.edge_attr.numpy(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert back to PyTorch tensors\n",
        "edge_attr_train = torch.tensor(edge_attr_train, dtype=torch.float)\n",
        "edge_attr_test = torch.tensor(edge_attr_test, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgTXLI_y9Iyp"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=0.2, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        # Apply an edge-based readout (combine node features at edge level)\n",
        "        edge_embeddings = x[edge_index[0]] * x[edge_index[1]]  # Combine features from both nodes at each edge\n",
        "        return edge_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRlM8dTXBWaV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Calculate the class weights for BCEWithLogitsLoss\n",
        "num_non_fraud = len(df[df['Is Fraud?'] == 0])\n",
        "num_fraud = len(df[df['Is Fraud?'] == 1])\n",
        "pos_weight = torch.tensor([num_non_fraud  / num_fraud * 0.8])  # Class imbalance adjustment\n",
        "\n",
        "# Define the model (GraphSAGE for example)\n",
        "model = GraphSAGE(in_channels=10, hidden_channels=128, out_channels=1)  # Output 1 for binary classification\n",
        "\n",
        "# Define the loss function with pos_weight\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Now, you can proceed with your training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itfzZN3kBYQu"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train(model, data, edge_index_train, edge_attr_train, y_train):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Create a new data object for the training set\n",
        "    data_train = Data(x=data.x, edge_index=edge_index_train, edge_attr=edge_attr_train, y=y_train)\n",
        "\n",
        "    # Get the edge-level predictions\n",
        "    out = model(data_train)\n",
        "\n",
        "    # Flatten the output to match the target shape (i.e., [batch_size] instead of [batch_size, 1])\n",
        "    out = out.view(-1)  # Flatten output\n",
        "\n",
        "    # Binary cross-entropy loss for edge-level prediction\n",
        "    loss = F.binary_cross_entropy_with_logits(out, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), out  # Return both loss and output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaGG_pxWBZTF"
      },
      "outputs": [],
      "source": [
        "# Testing loop\n",
        "def test(model, data, edge_index_test, edge_attr_test, y_test):\n",
        "    model.eval()\n",
        "\n",
        "    # Create a new data object for the test set\n",
        "    data_test = Data(x=data.x, edge_index=edge_index_test, edge_attr=edge_attr_test, y=y_test)\n",
        "\n",
        "    # Get the edge-level predictions\n",
        "    out = model(data_test)\n",
        "\n",
        "    # Flatten the output to match the target shape (i.e., [batch_size] instead of [batch_size, 1])\n",
        "    out = out.view(-1)  # Flatten output\n",
        "\n",
        "    # Binary cross-entropy loss for edge-level prediction\n",
        "    loss = F.binary_cross_entropy_with_logits(out, y_test)\n",
        "\n",
        "    # Apply sigmoid to get probabilities\n",
        "    out = torch.sigmoid(out)\n",
        "\n",
        "    # Binarize the predictions\n",
        "    y_pred = (out > 0.4).float()\n",
        "\n",
        "    # Calculate Precision, Recall, and F1 Score\n",
        "    precision = precision_score(y_test.cpu(), y_pred.cpu())\n",
        "    recall = recall_score(y_test.cpu(), y_pred.cpu())\n",
        "    f1 = f1_score(y_test.cpu(), y_pred.cpu())\n",
        "\n",
        "    return loss.item(), precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBU_JF9nBbsV",
        "outputId": "6012c7c8-71ed-4b56-8021-b869cbe6dbb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Training Loss: 0.7160100340843201\n",
            "Epoch 20, Training Loss: 0.6933155059814453\n",
            "Epoch 40, Training Loss: 0.6933906078338623\n",
            "Epoch 60, Training Loss: 0.69254469871521\n",
            "Epoch 80, Training Loss: 0.6919896602630615\n",
            "Epoch 100, Training Loss: 0.6904177665710449\n",
            "Epoch 120, Training Loss: 0.68715500831604\n",
            "Epoch 140, Training Loss: 0.6818499565124512\n",
            "Epoch 160, Training Loss: 0.6779442429542542\n",
            "Epoch 180, Training Loss: 0.6755403280258179\n",
            "Epoch 200, Training Loss: 0.6740038394927979\n",
            "Epoch 220, Training Loss: 0.6736592650413513\n",
            "Epoch 240, Training Loss: 0.6729025840759277\n",
            "Epoch 260, Training Loss: 0.6717182397842407\n",
            "Epoch 280, Training Loss: 0.6711723208427429\n",
            "Epoch 300, Training Loss: 0.6701749563217163\n",
            "Epoch 320, Training Loss: 0.6700023412704468\n",
            "Epoch 340, Training Loss: 0.6695899963378906\n",
            "Epoch 360, Training Loss: 0.6678500771522522\n",
            "Epoch 380, Training Loss: 0.6679631471633911\n",
            "Epoch 400, Training Loss: 0.6678508520126343\n",
            "Epoch 420, Training Loss: 0.6670271158218384\n",
            "Epoch 440, Training Loss: 0.6662328243255615\n",
            "Epoch 460, Training Loss: 0.6664021611213684\n",
            "Epoch 480, Training Loss: 0.6657819151878357\n",
            "Test Loss: 0.6194356679916382, Precision: 0.10251740760578468, Recall: 0.47540983606557374, F1 Score: 0.1686640817765245\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(500):\n",
        "    train_loss, _ = train(model, data, edge_index_train, edge_attr_train, y_train)\n",
        "    if epoch % 20 == 0:\n",
        "      print(f'Epoch {epoch}, Training Loss: {train_loss}')\n",
        "\n",
        "# After training, compute test metrics (Precision, Recall, F1)\n",
        "test_loss, precision, recall, f1 = test(model, data, edge_index_test, edge_attr_test, y_test)\n",
        "\n",
        "# Print test metrics\n",
        "print(f'Test Loss: {test_loss}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTK97YgGDGIc",
        "outputId": "a79ecf26-cd44-4f64-d81f-bc1e4a0a7148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of correctly predicted fraud cases: 698\n",
            "Total fraud cases: 2013\n",
            "Fraud detection rate (True Positive Rate): 0.35\n",
            "Test Loss: 0.6194356679916382\n",
            "Precision: 0.10507300918259822\n",
            "Recall: 0.34674615002483855\n",
            "F1 Score: 0.16127541589648797\n",
            "Accuracy: 0.637\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def test_and_verify(model, data, edge_index_test, edge_attr_test, y_test):\n",
        "    model.eval()\n",
        "\n",
        "    # Create a new data object for the test set\n",
        "    data_test = Data(x=data.x, edge_index=edge_index_test, edge_attr=edge_attr_test, y=y_test)\n",
        "\n",
        "    # Get the edge-level predictions\n",
        "    out = model(data_test)\n",
        "\n",
        "    # Flatten the output to match the target shape\n",
        "    out = out.view(-1)\n",
        "\n",
        "    # Binary cross-entropy loss for edge-level prediction\n",
        "    loss = F.binary_cross_entropy_with_logits(out, y_test)\n",
        "\n",
        "    # Apply sigmoid to get probabilities\n",
        "    out = torch.sigmoid(out)\n",
        "\n",
        "    # Binarize the predictions\n",
        "    y_pred = (out > 0.5).float()\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    precision = precision_score(y_test.cpu(), y_pred.cpu())\n",
        "    recall = recall_score(y_test.cpu(), y_pred.cpu())\n",
        "    f1 = f1_score(y_test.cpu(), y_pred.cpu())\n",
        "    accuracy = accuracy_score(y_test.cpu(), y_pred.cpu())\n",
        "\n",
        "    # Calculate the number of correctly predicted fraud cases\n",
        "    true_positives = ((y_pred == 1) & (y_test == 1)).sum().item()  # Predicted fraud correctly\n",
        "    total_fraud_cases = (y_test == 1).sum().item()  # Total actual fraud cases\n",
        "\n",
        "    print(f\"Number of correctly predicted fraud cases: {true_positives}\")\n",
        "    print(f\"Total fraud cases: {total_fraud_cases}\")\n",
        "    print(f\"Fraud detection rate (True Positive Rate): {true_positives / total_fraud_cases:.2f}\")\n",
        "\n",
        "    return loss.item(), precision, recall, f1, accuracy\n",
        "\n",
        "# After training, compute test metrics and verify fraud predictions\n",
        "test_loss, precision, recall, f1, accuracy = test_and_verify(\n",
        "    model, data, edge_index_test, edge_attr_test, y_test\n",
        ")\n",
        "\n",
        "# Print test metrics\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1478095,
          "sourceId": 2705785,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30357,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}